---
title: "Tipología y ciclo de vida de los datos"
subtitle: "Práctica 2: Limpieza y validación de los datos"
author: 'Autores: César Fernández Domínguez, Isabel Fernández Esparza'
date: "Junio 2019"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: Practica2-header.html
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```
```{r load_libraries, include=FALSE}
library(knitr)
library(lubridate)
library(stringr)
library(dplyr)
library(ggplot2)
library(grid)
library(gridExtra)
library(plyr)
library(cowplot)
library(colorspace)
library(mlbench)
library(caret)
library(car)
```

******
# Solución
******

## Descripción del dataset

Para la realización de esta práctica se ha seleccionado un conjunto de datos relacionado con resultados académicos de estudiantes de dos colegios de Portugal disponible en el repositorio de datos *kaggle*. En concreto este conjunto de datos se ha obtenido del enlace: https://www.kaggle.com/uciml/student-alcohol-consumption

Este dataset contiene información de estudiantes de matemáticas en edad de estudios secundarios. Se puede utilizar para analizar cómo afectan a los estudiantes de secundaria sus circunstancias personales a la hora de tener voluntad de continuar con estudios de mayor nivel. Estas circunstancias personales podemos entenderlas desde el punto de vista de: nivel de estudios de los padres, trabajo de los padres, si tienen pareja o no...

Por otro lado, también se podría hacer un análisis para estudiar la relación entre el número de suspensos de los estudiantes y el nivel de estudio de los padres, la distancia de los alumnos a los colegios, cómo influye el hecho de disponer de ayuda extraescolar en los resultados escolares, el tiempo de estudio semanal, el consumo de alcohol tanto diario como semanal, el número de ausencias...

Este conjunto de datos se presenta en dos ficheros distintos, en formato CSV: student-mad.csv (asignatura de matemáticas) y student-por.csv (asignatura de portugues), uno por cada asignatura.

El objetivo de esta práctica es limpiar los datos, unificarlos y poder estimar un modelo que pueda predecir el número de suspensos de un estudiante de matemáticas atendiendo a los factores anteriormente descritos. Teniendo en cuenta que en el juego de datos tenemos información de dos colegios diferentes podemos también intentar analizar si las predicciones realizadas están también sesgadas por el colegio al que pertenezcan los alumnos o por el sexo.

A continuación, se presenta una descripción de los atributos, para cada estudiante, contenidos en los dos ficheros:

 1. school - colegio al que pertenece el alumno (binario: 'GP' - Gabriel Pereira o 'MS' - Mousinho da Silveira)
 2. sex - sexo (binario: 'F' - mujer o 'M' - hombre)
 3. age - edad (numérico: entre 15 y 22 años)
 4. address - tipo de residencia (binario: 'U' - urbana o 'R' - rural)
 5. famsize - tamaño de la familia (binario: 'LE3' - menor o igual a 3 o 'GT3' - mayor que 3)
 6. Pstatus - padres separados o no (binario: 'T' - viven juntos o 'A' - separados)
 7. Medu - nivel educativo de la madre (numérico: 0 - ninguno, 1 - educación primaria (4º grado), 2 – entre 5º a 9º grado, 3 – educación secundaria o 4 – educación superior)
 8. Fedu - nivel educativo del padre (numérico: 0 - ninguno, 1 - educación primaria (4º grado), 2 – entre 5º a 9º grado, 3 – educación secundaria o 4 – educación superior)
 9. Mjob - trabajo de la madre (nominal: 'teacher', 'health' care related, civil 'services' (p.e. administrativa o policía), 'at_home' o 'other')
10. Fjob - trabajo del padre (nominal: 'teacher', 'health' care related, civil 'services' (p.e. administrativa o policía), 'at_home' o 'other')
11. reason - razón para elegir la escuela (nominal: cerca de 'home', school 'reputation', 'course' preferencia o 'other')
12. guardian - guardian del estudiante (nominal: 'mother', 'father' o 'other')
13. traveltime - tiempo de viaje desde casa a la escuela (numérico: 1 - <15 min., 2 - 15 a 30 min., 3 - 30 min. a 1 hour, o 4 - >1 hora)
14. studytime - tiempo de estudio semanal (numérico: 1 - <2 horas, 2 - 2 a 5 horas, 3 - 5 a 10 horas, o 4 - >10 horas)
15. failures - número de asignaturas suspensas (numérico: n si 1<=n<3, en cualquier otro caso 4)
16. schoolsup - apoyo educativo adicional (binario: yes o no)
17. famsup - ayuda educativa de la familia (binario: yes o no)
18. paid - clases privadas de las asignaturas (Matemáticas o Portugues) (binario: yes o no)
19. activities - actividades extra-escolares (binario: yes o no)
20. nursery - asistió a la guardería (binario: yes o no)
21. higher - el alumno quiere realizar estudios superiores (binario: yes o no)
22. internet - el alumno tiene Internet en casa (binario: yes o no)
23. romantic - el alumno tiene pareja o no (binario: yes o no)
24. famrel - calidad de la relación familiar (numérico: desde 1 - muy mal a 5 - excelente)
25. freetime - tiempo libre después de la escuela (numérico: desde 1 - muy poco a 5 - mucho)
26. goout - el alumno sale con amigo (numérico: desde 1 - muy poco a 5 - mucho)
27. Dalc - consumo de alcohol diario (numérico: desde 1 - muy poco a 5 - mucho)
28. Walc - consumo de alcohol durante el fin de semana (numérico: desde 1 - muy poco a 5 - mucho)
29. health - estado de salud del alumno (numérico: desde 1 - muy mal a 5 - muy bueno)
30. absences - número de ausencias del alumno (numérico: desde 0 a 93)

Además de los siguientes calificaciones relacionadas con las asignaturas de matemáticas y portugues:

31. G1 - calificación primer trimestre (numérico: entre 0 a 20)
32. G2 - calificación segundo trimestre (numérico: entre 0 a 20)
33. G3 - calificación tercer trimestre (numérico: entre 0 a 20)

## Importancia y objetivos de los análisis

Se plantea la necesidad de responder a las siguientes preguntas:

- ¿ Cuales son las variables que influyen más en la calificación de los estudiantes ?

- ¿ Predecir cuales serán la calificaciones de un estudiante en función de los otros atributos ? 

- Los alumnos que dedican más tiempo al estudio sacan mejores notas.
- Aquellos alumnos que van a clases particulares o reciben ayuda por parte de sus padres sacan mejores notas.
- En general, las chicas son mejores estudiantes que los chicos.

Estos análisis resultan de vital importancia tanto para el profesorado y dirección de una escuela, como para los padres de estudiantes. 



## Integración y selección de los datos de interés a analizar.

```{r message= FALSE, warning=FALSE}
sMat=read.table("data/student-mat.csv",sep=",",header=TRUE)
sPor=read.table("data/student-por.csv",sep=",",header=TRUE)

# Según el propietario de los datos, los alumnos que están presentes en ambas asignaturas 
# pueden ser identificados por los siguientes atributos
sBoth=merge(sMat,sPor,by=c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))

# school, sex, age, address, famsize, Pstatus, Medu, Fedu, Mjob, Fjob, reason, nursery, internet
# traveltime, studytime, failures, schoolsup, famsup, paid, activities, higher, romantic, famrel
# freetime, goout, Dalc, Walc, health, absences, subject
```

Ambos ficheros de datos de estudiantes contienen `r dim(sPor)[2]` atributos (columnas). El fichero de estudiantes de la asignatura de portugues contiene `r dim(sPor)[1]` estudiantes y, el de la asignatura de matemáticas `r dim(sMat)[1]` estudiantes. Si mezclamos ambos ficheros para obtener los alumnos que están en ambas asignaturas obtenemos un total de `r dim(sBoth)[1]` estudiantes.

Identificamos cada estudiante mediante los atributos indicados por el propietario del juego de datos. Generamos un identificador con la concatenación de estos atributos para cada estudiante. Después, en otro paso, convertiremos este identificador en un valor numérico que identifique a cada estudiante.

```{r message= FALSE, warning=FALSE}
sMat$id = paste(sMat$school,sMat$sex,sMat$age,sMat$address,sMat$famsize,sMat$Pstatus,sMat$Medu,sMat$Fedu,sMat$Mjob,sMat$Fjob,sMat$reason,sMat$nursery,sMat$internet, sep="-")
sPor$id = paste(sPor$school,sPor$sex,sPor$age,sPor$address,sPor$famsize,sPor$Pstatus,sPor$Medu,sPor$Fedu,sPor$Mjob,sPor$Fjob,sPor$reason,sPor$nursery,sPor$internet, sep="-")
```

Creamos una variable "score" que contendrá la media de las tres notas de los tres trimestres por cada alumno y asignatura. Luego, a partir de esta variable, creamos una variable categórica que exprese si un alumno ha aprobado o suspendido la asignatura.

5-Level classification – based on the Erasmus1 grade conversion system: 
```{r message= FALSE, warning=FALSE}
sMat$score = rowMeans(subset(sMat, select = c(G1, G2, G3)), na.rm = TRUE)
sMat$mark<-sMat$score
sMat$mark[sMat$score<10] <- "fail"
sMat$mark[sMat$score>=10] <- "pass"
sMat$mark <- as.factor(sMat$mark)
sMat$calification <- sMat$score
sMat$calification[(sMat$score<=20) & (sMat$score>=16)] <- "A"
sMat$calification[(sMat$score<16) & (sMat$score>=14)] <- "B"
sMat$calification[sMat$score<14 & sMat$score>=12] <- "C"
sMat$calification[sMat$score<12 & sMat$score>=10] <- "D"
sMat$calification[sMat$score<10] <- "F"
sMat$calification <- as.factor(sMat$calification)

sPor$score = rowMeans(subset(sPor, select = c(G1, G2, G3)), na.rm = TRUE)
sPor$mark<-sPor$score
sPor$mark[sPor$score<10] <- "fail"
sPor$mark[sPor$score>=10] <- "pass"
sPor$mark <- as.factor(sPor$mark)
sPor$calification <- sPor$score
sPor$calification[(sPor$score<=20) & (sPor$score>=16)] <- "A"
sPor$calification[(sPor$score<16) & (sPor$score>=14)] <- "B"
sPor$calification[sPor$score<14 & sPor$score>=12] <- "C"
sPor$calification[sPor$score<12 & sPor$score>=10] <- "D"
sPor$calification[sPor$score<10] <- "F"
sPor$calification <- as.factor(sPor$calification)
```

Vamos a crear un par de variables binarias nuevas para después unir los dos ficheros en un solo dataset:

```{r message= FALSE, warning=FALSE}

sMat$subject = 'Math'
sPor$subject = 'Portuguese'
students = rbind(sMat,sPor)
students$subject = as.factor(students$subject)
```

Ahora, a partir del identificador que anteriormente habiamos creado para cada estudiante, lo transformamos en un identificador numérico simple.

```{r message= FALSE, warning=FALSE}
students = transform(students, id=as.numeric(factor(id)))
students$id = as.factor(students$id)
```

Ahora tenemos un dataset con `r dim(students)[1]` instancias y `r dim(students)[2]` atributos para un total de `r length(unique(students$id))` estudiantes de ambas asignaturas.


```{r message= TRUE, warning=FALSE}
# Resumen
glimpse(students)
```

```{r message= TRUE, warning=FALSE}
# Estadísticas básicas
summary(students)
```

```{r message= TRUE, warning=FALSE}
# Tipo de dato asignado a cada campo
sapply(students, class)
```


## Limpieza de los datos

#### ¿Los datos tienen contienen ceros o elementos vacíos? ¿Cómo gestionaríamos cada uno de estos casos?

Primero vamos a comprobar si nuestro juego de datos contiene valores nulos.

```{r message= TRUE, warning=FALSE}
# Con datos nulos
colSums(is.na(students))
```

vemos que no existen valores vacíos.

Ahora vamos a comprobar si existen valores vacíos

```{r message= TRUE, warning=FALSE}
# Con datos ""
colSums(students=="")
```
Se observa que tampoco existen valores vacíos.

Luego como no existen nulos o elementos vacios no tenemos que hacer nada a este respecto.

Comprobamos, también, la existencia de valores cero. 

```{r message= TRUE, warning=FALSE}
colSums(students==0)
```

En este caso, vemos que algunos atributos contienen valores cero. Sin embargo, estos valores corresponden a variables numéricas y  comprobamos la validez los mismos.

Por último, visualizamos el número de valores únicos por cada atributo, comprobando su correspondencia con los datos.

```{r message= TRUE, warning=FALSE}
# Valores unicos
apply(students,2, function(x) length(unique(x)))
```

#### Identificación y tratamiento de valores extremos.

Los valores extremos o outliers son aquellas observaciones que están fuera de 1,5*IQR, donde IQR es la diferencia entre los cuartiles 75 y 25. Para buscar los outliers en nuestro juego de datos recorremos el dataset para encontrar todas aquellas variables numéricas y hacemos la representación gráfica de los outliers de cada una de ellas.

```{r message= TRUE, warning=FALSE}
par(mfrow=c(1,3))
for(i in 1:ncol(students)) {
  if (is.numeric(students[,i])){
    boxplot(students[,i], main = colnames(students)[i], width = 100)
  }
}
```


Vamos a analizar los diferentes outliers para cada una de las variables numéricas:

Hemos encontrado información interesante para el tratamiento de los outliers en la siguiente dirección web

https://www.ugr.es/~fmocan/MATERIALES%20DOCTORADO/Tratamiento%20de%20outliers%20y%20missing.pdf

Variable Age: Vemos que hay un outlier en el valor 22. En este caso consideramos que este valor no debería eliminarse y deberia tratarse como uno más, probablemente el hecho de que haya alumnos de 22 años en el mismos curso que alumnos de 18 años estará relacionado con algunas de las variables que queremos analizar, principalmente las notas.

Variables Medu y Fedu: No tienen valores extremos.

Variable traveltime: Vemos que hay un outlier en el valor 4. Es decir, se dan casos extremos en los que los alumnos tardan 4 horas en llegar al colegio. Vamos a ver cuántas veces se da este valor en nuestra muestra

```{r message= FALSE, warning=FALSE}
length(boxplot.stats(students[,c("traveltime")])$out)
```

Vemos que tenemos 24 alumnos que tardan más de 3 horas en ir al colegio. El tiempo que tardan los alumnos en llegar al colegio no es una varaiable sobre la que queramos realizar hipótesis, como además, el número total de outliers para este atributo es 24, esto representa el 2% de la muestra así que los eliminamos.

```{r message= FALSE, warning=FALSE}
students = students[students$traveltime<=3,]
```

La variable tiempo de estudio studytime vemos que también tiene un outlier en el valor 4. El tiempo de estudio de los alumnos sí que pensamos que es una variable que puede influir en los resultados finales y es una de los atributos que vamos a tener en cuenta en nuestros análisis. No consideramos que el 4 sea un outlier que haya ni que eliminar ni tratar puesto que es un valor aceptable para nuestro estudio, luego con este outlier no hacemos nada.

Lo mismo pasa con la variable que mide los suspensos, los valores que aparecen representados como outliers son precisamente los valores que pueden ser relevantes para nuestro estudio, luego no hacemos nada con ellos 

La variable freetime tiene un outlier en el valor 1, vamos a ver cuántos estudiantes cumplen esta condición. 

```{r message= FALSE, warning=FALSE}
students[students$freetime==1,]
```

Son 64 alumnos que tienen muy poco tiempo libre entre semana. Puesto que este valor está relacionado con el tiempo de estudio semanal y con las ayudas extrasescolares que puedan recibir los alumnos decidimos mantenerlos también.

Variable famrel: Tenemos outliers en 1 y 2. Estos valores miden la calidad de las relaciones familiares, entendiendo que estos valores se han obtenido a través de una encuesta a los propios alumnos.  El valor de 1 es tan bajo que pensamos que puede deberse a una manipulación por parte de los alumnos en las respuestas. Consideramos que una forma de tratar estos outliers es reemplazarlos por la moda (más repetida). Los valores de 2 los dejaremos como están puesto que no nos parece que puedan considrarse como outliers. Para calcular la moda utilizamos una tabla de frecuencia para contar el número de veces que se repite cada valor:

```{r message= FALSE, warning=FALSE}
table(students$famrel)
```

Vemos que el valor más repetido es el 4, luego sustituimos aquellas columnas que tengan el valor 1 en la columna famrel por 4

```{r message= FALSE, warning=FALSE}
students$famrel[students$famrel == 1] <- 4
```

En el caso del consumo diario de alcohol, tenemos un outlier en los valores 4 y 5. Sin embargo no tenemos estos outliers en el consumo del fin de semana. Pensamos por tanto que el hecho de que alumnos consuman mucho alcohol durante los días de diario puede estar relacionado con las notas que obtengan, así que vamos a dejar estos valores.

```{r message= FALSE, warning=FALSE}
length(boxplot.stats(students[,c("Dalc")])$out)
```

Para el caso de las ausencias, nos interesa saber cuántos outliers tenemos y qué valores toman para poder analizar cómo tratarlos.

```{r message= FALSE, warning=FALSE}
length(boxplot.stats(students[,c("absences")])$out)
boxplot.stats(students[,c("absences")])$out
students[students$absences>=40,]
```

A la vista de los resultados vemos que tenemos 54 outliers en las ausencias, y que los valores que toman en estos outliers son  16 16 25 54 18 26 20 18 16 16 56 24 18 28 22 16 18 20 16 21 75 22 30 19 20 38 18 20 22 40 23 16 17 16 16 24 22 16 32 
Nos parece que los valores que están en un intervalo de (10,30) son admisibles, sin embargo, vemos que hay valores que pasan de 40 que podrían eliminarse.

En total, vamos a contar cuántos datos tenemos para ausencias mayores o iguales que 40

```{r message= FALSE, warning=FALSE}
students[students$absences>=40,]
```

Vemos que tenemos 4 valores, luego decidimos eliminarlos de nuestro objeto de estudio

```{r message= FALSE, warning=FALSE}
students = students[students$absences<40,]
glimpse(students)
```

Las columnas relativas a las notas van a ser principalmente las que sean objeto de estudio. Tenemos outliers en notas que son perfectamente posibles, luego no vamos a eliminarlo puesto que pensamos que estos valores afectarán a los estudios e hipótesis que queramos estudiar.


## Análisis de los datos
  
### Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).

A continuación, se seleccionan los grupos dentro de nuestro conjunto de datos que pueden resultar interesantes para analizar y/o comparar. No obstante, como se verá en el apartado consistente en la realización de pruebas estadísticas, no todos se utilizarán.

```{r message= TRUE, warning=FALSE}
# school, sex, age, address, famsize, Pstatus, Medu, Fedu, Mjob, Fjob, reason, nursery, internet
# traveltime, studytime, failures, schoolsup, famsup, paid, activities, higher, romantic, famrel
# freetime, goout, Dalc, Walc, health, absences, subject

# Agrupación por sexo de los estudiantes
students.male <- students[students$sex == "M",]
students.female <- students[students$sex == "F",]

# Agrupación por si reciben clases particules pagadas o no
students.paid <- students[students$paid == "yes",]
students.nopaid <- students[students$paid == "no",]

# Agrupación por si reciben soporte por parte de la familia
students.famsup <- students[students$famsup == "yes",]
students.nofamsup <- students[students$famsup == "no",]

# Agrupación por si reciben ayuda extra escolar
students.schoolsup <- students[students$schoolsup == "yes",]
students.noschoolsup <- students[students$schoolsup == "no",]

# Agrupación por estudios de los padres
students.parentedu <- students[(students$Medu == "yes") | (students$Medu == "yes"),]
students.parentnoedu <- students[(students$Medu == "no") & (students$Medu == "no"),]

# Agrupación por tiempo dedicado al estudio
students.studytime <- students[students$studytime >= 3,]
students.nostudytime <- students[students$studytime < 3,]

# Agrupación por edad
students.mayores <- students[students$age >= 16,]
students.menores <- students[students$age < 16,]

# Agrupación por asignatura
students.port <- students[students$port == "yes",]
students.math <- students[students$math == "yes",]
```

### Análisis visual


```{r message= TRUE, warning=FALSE}
ggplot(students,aes(x=studytime,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
ggplot(students,aes(x=studytime,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
```

```{r message= TRUE, warning=FALSE}
ggplot(students,aes(x=schoolsup,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
ggplot(students,aes(x=schoolsup,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
```

```{r message= TRUE, warning=FALSE}
ggplot(students,aes(x=paid,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
ggplot(students,aes(x=paid,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
```

```{r message= TRUE, warning=FALSE}
ggplot(students,aes(x=famsup,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
ggplot(students,aes(x=famsup,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
```


### Comprobación de la normalidad y homogeneidad de la varianza
Para la comprobación de que los valores que toman nuestras variables cuantitativas provienen de una población distribuida normalmente, utilizaremos la prueba de normalidad de Anderson-Darling.
Así, se comprueba que para que cada prueba se obtiene un p-valor superior al nivel de significación prefijado α	$alpha$ = 0,05. Si esto se cumple, entonces se considera que la variable en cuestión sigue una distribución normal.

```{r message= TRUE, warning=FALSE}
# Tests de normalidad 
library(nortest)

# Función que aplica distintos test de homogeneidad sobre los datos de entrada
normTest <- function(data, name, alpha = 0.05) {
  ad_val = (ad.test(data)$p.value > alpha) # Anderson-Darling test
  ks_val = (ks.test(data, pnorm, mean(data), sd(data))$p.value > alpha) # Kolmogorov-Smirnov test
  sh_val = (shapiro.test(data)$p.value > alpha) # Shapiro test
  csv_val = (cvm.test(data)$p.value > alpha) # Cramer-von Mises test
  cat(name)
  cat("\t")
  cat(ad_val,ks_val,sh_val,csv_val,"\t")
  cat("\n")
}
```

```{r message= TRUE, warning=FALSE}
col.names = colnames(students)
cat("Distribucion normal: \n")
for (i in 1:ncol(students)) {
  if (is.integer(students[,i]) | is.numeric(students[,i])) {
    normTest(students[,i], col.names[i])
  }
}

```

Luego a la vista de los resultados obtenidos en los diferentes tests de normalidad, vemos que ninguna de las variables numéricas que tenemos en nuestro juego de datos sigue una distribución normal con respecto al conjunto total de los datos.

Ahora vamos a ver si estas variables numéricas siguen una distribución normal en cada uno de los grupos que hemos separado para realizar nuestro análisis. Es decir, vamos a ver si:

Hemos visto que las notas registradas no siguen una distrubución normal para el conjunto total de los datos pero, seguirán una distribución normal en el conjunto de hombres o de mujeres? ¿Y en el caso de que el tiempo de estudio sea de más de 3 horas o de menos? ¿Y de los alumnos mayores de 16 años o menores? ¿Y si separamos los datos entre alumnos que reciben clases particulares pagadas y no? ¿Y si reciben ayuda extraescolar de familia o en el colegio?

```{r message= TRUE, warning=FALSE}
normTest(students.female[,c("score")], "score~female")
normTest(students.male[,c("score")], "score~male")
normTest(students.studytime[,c("score")], "score~studytime")
normTest(students.nostudytime[,c("score")], "score~nostudytime")
normTest(students.mayores[,c("score")], "score~mayores")
normTest(students.menores[,c("score")], "score~menores")
normTest(students.paid[,c("score")], "score~paid")
normTest(students.nopaid[,c("score")], "score~nopaid")
normTest(students.schoolsup[,c("score")], "score~schoolsup")
normTest(students.noschoolsup[,c("score")], "score~noschoolsup")
normTest(students.famsup[,c("score")], "score~famsup")
normTest(students.nofamsup[,c("score")], "score~nofamsup")
```

Según los resultados obtenidos vemos que, para los alumnos menores de 16 años, las notas medias sí siguen una distribución normal, y para el caso de los que reciben clases particulares pagadas también así como para aquellos que reciben apoyo educativo adicional . Para el caso de las alumnas femeninas,y de los grupos que reciben o no reciben ayuda extraescolar familiar, el test de Kolmogorov sí indica que las variables de notas medias siguen una distribución normal

> Se utiliza el test de Fligner-Killeen, al no tener normalidad en los datos. 
> Se utilizaría el test Levene cuando hay normalidad en los datos.

Vamos a estudiar ahora la homogeneidad de la varianza para los diferentes grupos que queremos analizar. En primer lugar vamos a analizar la homocedasticidad entre niños y niñas. Vimos en el apartado anterior que esta variable no sigue una distribución normal para estos grupos, luego para realizar nuestro análisis utilizaremos el test de Fligner-Killeen.


```{r message= TRUE, warning=FALSE}
fligner.test(score ~ sex, data = students)
```

Vemos, por tanto, que el valor de p obtenido (p-value) es mayor que 0,05 luego esto indica que no se observa diferencia significativa entre las varianzas por grupos de sexo.

Vamos a aplicar el test de Levene para ver que resultado obtenemos en este caso:

```{r message= TRUE, warning=FALSE}
leveneTest(score ~ sex, data = students)
```

Para este caso también se cumpliría que el valor de p es mayor de 0,05 luego también indicaría que no existe diferencia significativa entre las varianzas

Veamos ahora cómo se distribuye la varianza para la media escolar entre los grupos de alumnos que reciben clases privadas de las asignaturas. Nuevamente, como estos valores no siguen una distribución normal, utilizaremos el test de Fligner-Killeen

```{r message= TRUE, warning=FALSE}
fligner.test(score ~ paid, data = students)
```

Nuevamente, vemos que el valor de p es mayor de 0.05, luego podemos concluir que las varianzas están homogéneamente distrubuidas.

Si aplicamos es test de Levene

```{r message= TRUE, warning=FALSE}
leveneTest(score ~ paid, data = students)
```

Vemos también el mismo resultado

Si ahora analizamos las distribuciones atendiendo a si reciben clases estraescolares o ayudas de sus padres, vamos a ver qué obtenemos, nuevamente aplicando el test de Fligner-Killeen por la falta de normalidad en nuestros datos.

```{r message= TRUE, warning=FALSE}
fligner.test(score ~ schoolsup, data = students)
```

En este caso vemos que el valor de p obtenido es menor que 0,05 luego vemos que la variable score (que recoge las medias de todas las notas obtenidas) presenta varianzas estadísticamente diferentes para los grupos de alumnos que reciben ayuda extraescolar o no en el colegio.

Vamos a ver qué resultados obtenemos para este caso utilizando el test de Levene

```{r message= TRUE, warning=FALSE}
leveneTest(score ~ schoolsup, data = students)
```

Nuevamente el valor es menor que 0.05

Analicemos ahora cómo se distribuye la varianza de las notas medias para los grupos de alumnos que reciben ayuda suplementaria en casa. Nuevamente, usamos el test de Fligner-Killeen

```{r message= TRUE, warning=FALSE}
fligner.test(score ~ famsup, data = students)
```

En este caso, se observa que el valor de p (p-value) es mayor de 0,05 luego podemos concluir que las varianzas son homogéneas para estos grupos de estudiantes

Analicemos cómo se distribuye la varianza de las notas medias por los diferentes grupos de edad, entre los alumnos menores de 16 y los mayores de 16

```{r message= TRUE, warning=FALSE}
a <- students[students$age < 16,"score"]
b <- students[students$age >= 16,"score"]
fligner.test(x = list(a,b))
```

El valor de p que obtenemos es menor que 0.05 lyego rechazamos la hipótesis de homocedasticidad y concluimos que la variable score tiene varianzas estadísticamente diferentes para los alumnos menores de 16 y los mayores de 16.

Por último estudiaremos la distribución de la varianza para los grupos de alumnos que estudian más o menos de 3 horas.

```{r message= TRUE, warning=FALSE}
a <- students[students$studytime < 3,"score"]
b <- students[students$studytime >= 3,"score"]
fligner.test(x = list(a,b))
```

El valor de p es mayor de 0.05 luego podemos concluir que sí existe homogeneidad de la varianza

Vamos a representar los histogramas de estas variables

```{r message= TRUE, warning=FALSE}
plotNormHistogram <- function(data, name) {
    qqnorm(data,main = paste("Normal Q-Q Plot for ",name))
    qqline(data,col="red")
    hist(data, 
      main=paste("Histogram for ", name), 
      xlab=name, freq = FALSE)
}
```

```{r message= TRUE, warning=FALSE}
par(mfrow=c(2,2))
for(i in 1:ncol(students)) {
  if (is.numeric(students[,i])){
    plotNormHistogram(students[,i], colnames(students)[i])
  }
}
```
```{r message= TRUE, warning=FALSE}
par(mfrow=c(2,2))
plotNormHistogram(students.female[,c("score")], "score~sex")
plotNormHistogram(students.male[,c("score")], "score~sex")
plotNormHistogram(students.studytime[,c("score")], "score~studytime")
plotNormHistogram(students.nostudytime[,c("score")], "score~studytime")
plotNormHistogram(students.mayores[,c("score")], "score~mayores")
plotNormHistogram(students.menores[,c("score")], "score~menores")
```


## Pruebas estadísticas

Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

### Correlaciones

```{r message= TRUE, warning=FALSE}
color=diverge_hcl(length(students$calification))[rank(students$calification)]
pairs(~ G1 + G2 + G3 + score, data = students, pch = 19, cex = 0.5, lower.panel = NULL, col = color)
title("Correlación notas")
```

Luego, a la vista de estos diagramas, parece intuirse que existe una posible relación lineal entre las notas de cada trimestre.

Como ya hemos visto que estas variables no siguen una distribución normal, vamos a analizar la correlación utilizando el test de Spearman

```{r message= FALSE, warning=FALSE}
cor(x = students$G1, y = log10(students$G2), method = "spearman")
cor(x = students$G1, y = log10(students$G3), method = "spearman")
cor(x = students$G1, y = log10(students$score), method = "spearman")
cor(x = students$G2, y = log10(students$G3), method = "spearman")
cor(x = students$G2, y = log10(students$score), method = "spearman")
cor(x = students$G3, y = log10(students$score), method = "spearman")
```

Vemos que para los 4 casos el grado de correlación es alto (mayor que 0,8). Pero para poder realmente considerar que existe correlación entre las variables debemos calcular la significancia

```{r message= FALSE, warning=FALSE}
# https://rpubs.com/Joaquin_AR/223351
cor.test(x = students$G1,
         y = log10(students$G2),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = students$G1,
         y = log10(students$G3),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = students$G1,
         y = log10(students$score),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = students$G2,
         y = log10(students$G3),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = students$G2,
         y = log10(students$score),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = students$G3,
         y = log10(students$score),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")
```

Vemos que, para todos los casos, los coeficientes de correlación son significativos puesto que p está próximo a 0 en los tres casos.


### ¿Las chicas sacan mejores notas que los chicos?


```{r message= TRUE, warning=FALSE}
t.test(students.male$score, students.female$score, alternative = "less")
```

### ¿Quien más tiempo dedica al estudio saca mejores notas?

```{r message= TRUE, warning=FALSE}
t.test(students.nostudytime$score, students.studytime$score, alternative = "less")
```

## Aquellos alumnos que van a clases particulares o reciben ayuda por parte de sus padres sacan mejores notas

### Modelo lineal

```{r message= TRUE, warning=FALSE}
smp_siz = floor(0.75*nrow(students))

set.seed(123)   # set seed to ensure you always have same random numbers generated
train_ind = sample(seq_len(nrow(students)),size = smp_siz)  # Randomly identifies the rows equal to sample size ( defined in previous instruction) from  all the rows of Smarket dataset and stores the row number in train_ind
train = students[train_ind,] #creates the training dataset with row numbers stored in train_ind
test = students[-train_ind,]  # creates the test dataset excluding the row numbers mentioned in train_ind
```

```{r message= TRUE, warning=FALSE}

# Generación de varios modelos
modelo1 <- lm(score ~ G1, data = train)
modelo2 <- lm(score ~ G1 + G2, data = train)
modelo3 <- lm(score ~ G1 + G2 + G3, data = train)
modelo4 <- lm(score ~ G1 + G3, data = train)
modelo5 <- lm(score ~ G1 + G3 + studytime, data = train)
modelo6 <- lm(score ~ studytime + sex + absences, data = train)
modelo7 <- lm(score ~ studytime + paid, data = train)
modelo8 <- lm(score ~ G1 + G3 + studytime + paid, data = train)

tabla.coeficientes <- matrix(
    c(1, summary(modelo1)$r.squared,
      2, summary(modelo2)$r.squared,
      3, summary(modelo3)$r.squared,
      4, summary(modelo4)$r.squared,
      5, summary(modelo5)$r.squared,
      6, summary(modelo6)$r.squared,
      7, summary(modelo7)$r.squared,
      8, summary(modelo8)$r.squared),
    ncol = 2, byrow = TRUE)
colnames(tabla.coeficientes) <- c("Modelo", "R^2")
tabla.coeficientes
```
```{r message= TRUE, warning=FALSE}
summary(modelo1)
```
```{r message= TRUE, warning=FALSE}
y_predict = predict(modelo8, test)
```
```{r message= TRUE, warning=FALSE}
plot(test$score, col = "green", xlab = "", ylab = "", ylim = range(0,15)) 
points(y_predict, col = "blue") 
legend("bottom", c("real", "predicted"), pch = "o", col = c("green", "blue"), trace = TRUE)
```

## Regresión logística
Vamos a utilizar regresión logística para intentar averiguar qué variable de las categóricas con las que hemos estado trabajando puede predecirse mejor a partir de la nota media dle curso. Vamos a generar modelos de regresión logística para distintas variables dicotómicas, y vamos a ver cuál de ellos es mejor.

Nos centraremos en las siguientes variables:

- Sexo: podemos predecir el sexo del alumno en función de la nota?
- SchoolSup: podemos predecir si el alumno ha tenido ayuda en la escuela en función de la nota media?
- famSup: podemos predecir si el alumno ha tenido ayuda en casa en función de la nota media?
- higher: Podemos predecir si el alumno querrá seguir estudiando en función de la nota media obtenida?




En primer lugar vamos a representar las observaciones para cada uno de estos casos para poder intuir gráficamente si la varibale escogida (la media de las notas: score) está relacionada con la variable respuesta (obtienen ayuda escolar) y puede considerarse que es un buen predictor

```{r message= FALSE, warning=FALSE}
par(mfrow=c(2,2))
ggplot(data = students, aes(x = sex, y = score, color = sex)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")

ggplot(data = students, aes(x = schoolsup, y = score, color = schoolsup)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")

ggplot(data = students, aes(x = famsup, y = score, color = famsup)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")


ggplot(data = students, aes(x = higher, y = score, color = higher)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")
```

A la vista de las gráficas, parece que en el único caso en el que se aprecian diferencias significativas en las notas es en el caso en el que los estudiantes quieren seguir estudiando.


Ahora vamos a generar los modelos para cada una de ellas a ver qué obtenemos

```{r message= FALSE, warning=FALSE}
m1 <- glm(sex ~ score, data = students, family = "binomial")
summary(m1)

m2 <- glm(schoolsup ~ score, data = students, family = "binomial")
summary(m2)

m3 <- glm(famsup ~ score, data = students, family = "binomial")
summary(m3)


m4 <- glm(higher ~ score, data = students, family = "binomial")
summary(m4)
```

Se observa que el AIC (criterio de información de Akaike) menor de los 4 modelos es el correspondiente al hecho de querer cursar estudios superiores


## Conclusiones

Hemos partido de un conjunto de datos de alumnos esudiantes de matemáticas y portugués en los que se recogía información de diferentes aspectos: el sexo de los alumnos, el número de suspensos, si reciben ayuda extra en sus estudios ya sea esta en el colegio, pagada por sus padres, si quieren continuar con sus estudios, y las notas obtenidas durante los tres trimestres.

Teníamos los datos de dos ficheros csv, uno para los datos de matemáticas y otro para los de portugés. Como primer paso, hemos unido ambos conjuntos en un único data set añadiendo una nueva columna indicando la asignatura de la que provenían. Una vez que los teníamos juntos hemos creado una varibale numérica nueva con la media de todas las notas y otra variable categórica asociando esa nota media a una nota categorizada (A, B, C, D, E y F). Tras comprobar que no existian valores nulos ni vacíos, hemos analizado los outliers que había en cada variable numérica y hemos tratado particularmente cada uno de ellos, teniendo en cuenta la relevancia de los mismos para cada uno de los casos.

El objetivo de nuestro estudio es saber si existe alguna variable en el juego de datos que pueda ayudarnos a predecir las notas. 

En primer lugar hemos analizado la correlación entre las notas: vemos que lo están, es decir, que las notas de cada alumno en cada trimestre están determinadas fuertemente por las obtenidas en los anteriores, es decir, que un estudiante que saca buenas notas en el primer trimestre es muy probable que saque buenas notas en los siguientes.

Además, hemos usado regresión logística para poder saber si las notas pueden determinar alguna de estas características, hemos intentando averiguar cuál de las variables binarias que tenemos puede estar determinada por las notas obtenidas y vemos que de todas las que hemos analizado, la más determinada es la voluntad del estudiante de continuar con cursos superiores, es decir, que podemos ver que un estudiante que ha obtenido una nota alta es probable que continúe sus estudios. Luego parece lógico pensar que un alumno que quiere continuar estudiando tendrá buenas calificaciones.


# Recursos

Los siguientes recursos son de utilidad para la realización de la práctica:
● Calvo M., Subirats L., Pérez D. (2019). Introducción a la limpieza y análisis de los datos.
Editorial UOC.
● Megan Squire (2015). Clean Data. Packt Publishing Ltd.
● Jiawei Han, Micheine Kamber, Jian Pei (2012). Data mining: concepts and techniques.
Morgan Kaufmann.
● Jason W. Osborne (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme
Scores. Newborn and Infant Nursing Reviews; 10 (1): pp. 1527-3369.
● Peter Dalgaard (2008). Introductory statistics with R. Springer Science & Business Media.
● Wes McKinney (2012). Python for Data Analysis. O’Reilley Media, Inc.
● Tutorial de Github https://guides.github.com/activities/hello-world.


  





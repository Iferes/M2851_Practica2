---
title: "Tipología y ciclo de vida de los datos"
subtitle: "Práctica 2: Limpieza y validación de los datos"
author: 'Autores: César Fernández Domínguez, Isabel Fernández Esparza'
date: "Junio 2019"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: Practica2-header.html
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```
```{r load_libraries, include=FALSE}
library(knitr)
library(lubridate)
library(stringr)
library(dplyr)
library(ggplot2)
library(grid)
library(gridExtra)
library(plyr)
library(cowplot)
library(colorspace)
library(mlbench)
library(caret)
library(car)
```

******
# Solución
******

## Descripción del dataset

Para la realización de esta práctica se ha seleccionado un conjunto de datos relacionado con resultados académicos de estudiantes de dos colegios de Portugal disponible en el repositorio de datos *kaggle*. En concreto este conjunto de datos se ha obtenido del enlace: https://www.kaggle.com/uciml/student-alcohol-consumption

Este dataset contiene información de estudiantes de matemáticas en edad de estudios secundarios. Se puede utilizar para analizar cómo afectan a los estudiantes de secundaria sus circunstancias personales a la hora de tener voluntad de continuar con estudios de mayor nivel. Estas circunstancias personales podemos entenderlas desde el punto de vista de: nivel de estudios de los padres, trabajo de los padres, si tienen pareja o no...

Por otro lado, también se podría hacer un análisis para estudiar la relación entre el número de suspensos de los estudiantes y el nivel de estudio de los padres, la distancia de los alumnos a los colegios, cómo influye el hecho de disponer de ayuda extraescolar en los resultados escolares, el tiempo de estudio semanal, el consumo de alcohol tanto diario como semanal, el número de ausencias...

Este conjunto de datos se presenta en dos ficheros distintos, en formato CSV: student-mad.csv (asignatura de matemáticas) y student-por.csv (asignatura de portugues), uno por cada asignatura.

El objetivo de esta práctica es limpiar los datos, unificarlos y poder estimar un modelo que pueda predecir el número de suspensos de un estudiante de matemáticas atendiendo a los factores anteriormente descritos. Teniendo en cuenta que en el juego de datos tenemos información de dos colegios diferentes podemos también intentar analizar si las predicciones realizadas están también sesgadas por el colegio al que pertenezcan los alumnos o por el sexo.

A continuación, se presenta una descripción de los atributos, para cada estudiante, contenidos en los dos ficheros:

 1. school - colegio al que pertenece el alumno (binario: 'GP' - Gabriel Pereira o 'MS' - Mousinho da Silveira)
 2. sex - sexo (binario: 'F' - mujer o 'M' - hombre)
 3. age - edad (numérico: entre 15 y 22 años)
 4. address - tipo de residencia (binario: 'U' - urbana o 'R' - rural)
 5. famsize - tamaño de la familia (binario: 'LE3' - menor o igual a 3 o 'GT3' - mayor que 3)
 6. Pstatus - padres separados o no (binario: 'T' - viven juntos o 'A' - separados)
 7. Medu - nivel educativo de la madre (numérico: 0 - ninguno, 1 - educación primaria (4º grado), 2 – entre 5º a 9º grado, 3 – educación secundaria o 4 – educación superior)
 8. Fedu - nivel educativo del padre (numérico: 0 - ninguno, 1 - educación primaria (4º grado), 2 – entre 5º a 9º grado, 3 – educación secundaria o 4 – educación superior)
 9. Mjob - trabajo de la madre (nominal: 'teacher', 'health' care related, civil 'services' (p.e. administrativa o policía), 'at_home' o 'other')
10. Fjob - trabajo del padre (nominal: 'teacher', 'health' care related, civil 'services' (p.e. administrativa o policía), 'at_home' o 'other')
11. reason - razón para elegir la escuela (nominal: cerca de 'home', school 'reputation', 'course' preferencia o 'other')
12. guardian - guardian del estudiante (nominal: 'mother', 'father' o 'other')
13. traveltime - tiempo de viaje desde casa a la escuela (numérico: 1 - <15 min., 2 - 15 a 30 min., 3 - 30 min. a 1 hour, o 4 - >1 hora)
14. studytime - tiempo de estudio semanal (numérico: 1 - <2 horas, 2 - 2 a 5 horas, 3 - 5 a 10 horas, o 4 - >10 horas)
15. failures - número de asignaturas suspensas (numérico: n si 1<=n<3, en cualquier otro caso 4)
16. schoolsup - apoyo educativo adicional (binario: yes o no)
17. famsup - ayuda educativa de la familia (binario: yes o no)
18. paid - clases privadas de las asignaturas (Matemáticas o Portugues) (binario: yes o no)
19. activities - actividades extra-escolares (binario: yes o no)
20. nursery - asistió a la guardería (binario: yes o no)
21. higher - el alumno quiere realizar estudios superiores (binario: yes o no)
22. internet - el alumno tiene Internet en casa (binario: yes o no)
23. romantic - el alumno tiene pareja o no (binario: yes o no)
24. famrel - calidad de la relación familiar (numérico: desde 1 - muy mal a 5 - excelente)
25. freetime - tiempo libre después de la escuela (numérico: desde 1 - muy poco a 5 - mucho)
26. goout - el alumno sale con amigo (numérico: desde 1 - muy poco a 5 - mucho)
27. Dalc - consumo de alcohol diario (numérico: desde 1 - muy poco a 5 - mucho)
28. Walc - consumo de alcohol durante el fin de semana (numérico: desde 1 - muy poco a 5 - mucho)
29. health - estado de salud del alumno (numérico: desde 1 - muy mal a 5 - muy bueno)
30. absences - número de ausencias del alumno (numérico: desde 0 a 93)

Además de los siguientes calificaciones relacionadas con las asignaturas de matemáticas y portugues:

31. G1 - calificación primer trimestre (numérico: entre 0 a 20)
32. G2 - calificación segundo trimestre (numérico: entre 0 a 20)
33. G3 - calificación tercer trimestre (numérico: entre 0 a 20)

## Importancia y objetivos de los análisis

Se plantea la necesidad de responder a las siguientes preguntas:

- ¿ Cuales son las variables que influyen más en la calificación de los estudiantes ?

- ¿ Predecir cuales serán la calificaciones de un estudiante en función de los otros atributos ? 

- Los alumnos que dedican más tiempo al estudio sacan mejores notas.
- Aquellos alumnos que van a clases particulares o reciben ayuda por parte de sus padres sacan mejores notas.
- En general, las chicas son mejores estudiantes que los chicos.

Estos análisis resultan de vital importancia tanto para el profesorado y dirección de una escuela, como para los padres de estudiantes. 



## Integración y selección de los datos de interés a analizar.

```{r message= FALSE, warning=FALSE}
sMat=read.table("data/student-mat.csv",sep=",",header=TRUE)
sPor=read.table("data/student-por.csv",sep=",",header=TRUE)

# Según el propietario de los datos, los alumnos que están presentes en ambas asignaturas 
# pueden ser identificados por los siguientes atributos
sBoth=merge(sMat,sPor,by=c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))

# school, sex, age, address, famsize, Pstatus, Medu, Fedu, Mjob, Fjob, reason, nursery, internet
# traveltime, studytime, failures, schoolsup, famsup, paid, activities, higher, romantic, famrel
# freetime, goout, Dalc, Walc, health, absences, subject
```

Ambos ficheros de datos de estudiantes contienen `r dim(sPor)[2]` atributos (columnas). El fichero de estudiantes de la asignatura de portugues contiene `r dim(sPor)[1]` estudiantes y, el de la asignatura de matemáticas `r dim(sMat)[1]` estudiantes. Si mezclamos ambos ficheros para obtener los alumnos que están en ambas asignaturas obtenemos un total de `r dim(sBoth)[1]` estudiantes.

Identificamos cada estudiante mediante los atributos indicados por el propietario del juego de datos. Generamos un identificador con la concatenación de estos atributos para cada estudiante. Después, en otro paso, convertiremos este identificador en un valor numérico que identifique a cada estudiante.

```{r message= FALSE, warning=FALSE}
sMat$id = paste(sMat$school,sMat$sex,sMat$age,sMat$address,sMat$famsize,sMat$Pstatus,sMat$Medu,sMat$Fedu,sMat$Mjob,sMat$Fjob,sMat$reason,sMat$nursery,sMat$internet, sep="-")
sPor$id = paste(sPor$school,sPor$sex,sPor$age,sPor$address,sPor$famsize,sPor$Pstatus,sPor$Medu,sPor$Fedu,sPor$Mjob,sPor$Fjob,sPor$reason,sPor$nursery,sPor$internet, sep="-")
```

Creamos una variable "score" que contendrá la media de las tres notas de los tres trimestres por cada alumno y asignatura. Luego, a partir de esta variable, creamos una variable categórica que exprese si un alumno ha aprobado o suspendido la asignatura.

5-Level classification – based on the Erasmus1 grade conversion system: 
```{r message= FALSE, warning=FALSE}
sMat$score = rowMeans(subset(sMat, select = c(G1, G2, G3)), na.rm = TRUE)
sMat$mark<-sMat$score
sMat$mark[sMat$score<10] <- "fail"
sMat$mark[sMat$score>=10] <- "pass"
sMat$mark <- as.factor(sMat$mark)
sMat$calification <- sMat$score
sMat$calification[(sMat$score<=20) & (sMat$score>=16)] <- "A"
sMat$calification[(sMat$score<16) & (sMat$score>=14)] <- "B"
sMat$calification[sMat$score<14 & sMat$score>=12] <- "C"
sMat$calification[sMat$score<12 & sMat$score>=10] <- "D"
sMat$calification[sMat$score<10] <- "F"
sMat$calification <- as.factor(sMat$calification)

sPor$score = rowMeans(subset(sPor, select = c(G1, G2, G3)), na.rm = TRUE)
sPor$mark<-sPor$score
sPor$mark[sPor$score<10] <- "fail"
sPor$mark[sPor$score>=10] <- "pass"
sPor$mark <- as.factor(sPor$mark)
sPor$calification <- sPor$score
sPor$calification[(sPor$score<=20) & (sPor$score>=16)] <- "A"
sPor$calification[(sPor$score<16) & (sPor$score>=14)] <- "B"
sPor$calification[sPor$score<14 & sPor$score>=12] <- "C"
sPor$calification[sPor$score<12 & sPor$score>=10] <- "D"
sPor$calification[sPor$score<10] <- "F"
sPor$calification <- as.factor(sPor$calification)
```

Vamos a crear un par de variables binarias nuevas para después unir los dos ficheros en un solo dataset:

```{r message= FALSE, warning=FALSE}

sMat$subject = 'Math'
sPor$subject = 'Portuguese'
students = rbind(sMat,sPor)
students$subject = as.factor(students$subject)
```

Ahora, a partir del identificador que anteriormente habiamos creado para cada estudiante, lo transformamos en un identificador numérico simple.

```{r message= FALSE, warning=FALSE}
students = transform(students, id=as.numeric(factor(id)))
students$id = as.factor(students$id)
```

Ahora tenemos un dataset con `r dim(students)[1]` instancias y `r dim(students)[2]` atributos para un total de `r length(unique(students$id))` estudiantes de ambas asignaturas.


```{r message= TRUE, warning=FALSE}
# Resumen
glimpse(students)
```

```{r message= TRUE, warning=FALSE}
# Estadísticas básicas
summary(students)
```

```{r message= TRUE, warning=FALSE}
# Tipo de dato asignado a cada campo
sapply(students, class)
```


## Limpieza de los datos

#### ¿Los datos tienen contienen ceros o elementos vacíos? ¿Cómo gestionaríamos cada uno de estos casos?

Primero vamos a comprobar si nuestro juego de datos contiene valores vacíos.

```{r message= TRUE, warning=FALSE}
# Con datos nulos
colSums(is.na(students))
```

vemos que no existen valores vacíos.

Ahora vamos a comprobar si existen valores vacíos

```{r message= TRUE, warning=FALSE}
# Con datos ""
colSums(students=="")
```
Se observa que tampoco existen valores vacíos.

Luego como no existen nulos o elementos vacios no tenemos que hacer nada a este respecto.

Comprobamos, también, la existencia de valores cero. 

```{r message= TRUE, warning=FALSE}
colSums(students==0)
```

En este caso, vemos que algunos atributos contienen valores cero. Sin embargo, comprobamos la validez de estos valores.

Por último, visualizamos el número de valores únicos por cada atributo, comprobando su correspondencia con los datos.

```{r message= TRUE, warning=FALSE}
# Valores unicos
apply(students,2, function(x) length(unique(x)))
```

#### Identificación y tratamiento de valores extremos.

Los valores extremos o outliers son aquellas observaciones que están fuera de 1,5*IQR, donde IQR es la diferencia entre los cuartiles 75 y 25. Para buscar los outliers en nuestro juego de datos recorremos el dataset para encontrar todas aquellas variables numéricas y hacemos la representación gráfica de los outliers de cada una de ellas.

```{r message= TRUE, warning=FALSE}
par(mfrow=c(1,3))
for(i in 1:ncol(students)) {
  if (is.numeric(students[,i])){
    boxplot(students[,i], main = colnames(students)[i], width = 100)
  }
}
```


Vamos a analizar los diferentes outliers para cada una de las variables numéricas:

Hemos encontrado información interesante para el tratamiento de los outliers en la siguiente dirección web

https://www.ugr.es/~fmocan/MATERIALES%20DOCTORADO/Tratamiento%20de%20outliers%20y%20missing.pdf

Variable Age: Vemos que hay un outlier en el valor 22. En este caso consideramos que este valor no debería eliminarse y deberia tratarse como uno más, probablemente el hecho de que haya alumnos de 22 años en el mismos curso que alumnos de 18 años estará relacionado con algunas de las variables que queremos analizar.

Variables Medu y Fedu: No tienen valores extremos.

Variable traveltime: Vemos que hay un outlier en el valor 4. Es decir, se dan casos extremos en los que los alumnos tardan 4 horas en llegar al colegio. Vamos a ver cuántas veces se da este valor en nuestra muestra

```{r message= FALSE, warning=FALSE}
length(boxplot.stats(students[,c("traveltime")])$out)
```

```{r message= FALSE, warning=FALSE}
length(boxplot.stats(students[,c("absences")])$out)
students[students$absences>=40,]
```

```{r message= FALSE, warning=FALSE}
students[students$traveltime>3,]
```

Tenemos solo 24 registros de alumnos que tardan más de 3 horas (es decir, 4) al colegio. Entendemos esta observación como consecuencia de un acontecimiento extraordinario, luego podemos prescindir de estos valores para nuestro análisis. 

```{r message= FALSE, warning=FALSE}
# Nos quedamos entonces solo con los datos de alumnos que tardan como máximo 3 horas en llegar a la escuela.
students = students[students$traveltime<=3,]
str(students)
```

Variable studytime: Tenemos outliers en el valor 4. Aunque este valos se sale de la media, la diferencia entre el resto de valores es solo de una hora, luego no nos parece que sea un outlier como tal, asi que vamos a dejarlo como está.

Variable failures: Nos ocurre lo mismo que en el caso anterior, los valores que aparecen señalados como outliers son precisamente objetos fundamentales de nuestro análisis y no debemos tratarlos como tal.

Variable famrel: Tenemos outliers en 1 y 2. Estos valores miden la calidad de las relaciones familiares, entendiendo que estos valores se han obtenido a través de una encuesta a los propios alumnos.  Estos valores tan bajos en algunas calificaciones pueden deberse a una manipulación por parte de los alumnos en las respuestas. Consideramos que una forma de tratar estos outliers es reemplazarlos por la media.

```{r message= FALSE, warning=FALSE}
str(students)
```


Variable freetime: Existe un outlier en el valor 1

## Análisis de los datos
  
### Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).

A continuación, se seleccionan los grupos dentro de nuestro conjunto de datos que pueden resultar interesantes para analizar y/o comparar. No obstante, como se verá en el apartado consistente en la realización de pruebas estadísticas, no todos se utilizarán.

```{r message= TRUE, warning=FALSE}
# school, sex, age, address, famsize, Pstatus, Medu, Fedu, Mjob, Fjob, reason, nursery, internet
# traveltime, studytime, failures, schoolsup, famsup, paid, activities, higher, romantic, famrel
# freetime, goout, Dalc, Walc, health, absences, subject

# Agrupación por sexo de los estudiantes
students.male <- students[students$sex == "M",]
students.female <- students[students$sex == "F",]

# Agrupación por si reciben clases particules pagadas o no
students.paid <- students[students$paid == "yes",]
students.nopaid <- students[students$paid == "no",]

# Agrupación por si reciben soporte por parte de la familia
students.famsup <- students[students$famsup == "yes",]
students.nofamsup <- students[students$famsup == "no",]

# Agrupación por si reciben ayuda extra escolar
students.schoolsup <- students[students$schoolsup == "yes",]
students.noschoolsup <- students[students$schoolsup == "no",]

# Agrupación por estudios de los padres
students.parentedu <- students[(students$Medu == "yes") | (students$Medu == "yes"),]
students.parentnoedu <- students[(students$Medu == "no") & (students$Medu == "no"),]

# Agrupación por tiempo dedicado al estudio
students.studytime <- students[students$studytime >= 3,]
students.nostudytime <- students[students$studytime < 3,]

# Agrupación por edad
students.mayores <- students[students$age >= 16,]
students.menores <- students[students$age < 16,]

# Agrupación por asignatura
students.port <- students[students$port == "yes",]
students.math <- students[students$math == "yes",]
```

### Análisis visual


```{r message= TRUE, warning=FALSE}
ggplot(students,aes(x=studytime,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
ggplot(students,aes(x=studytime,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
```

```{r message= TRUE, warning=FALSE}
ggplot(students,aes(x=schoolsup,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
ggplot(students,aes(x=schoolsup,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
```

```{r message= TRUE, warning=FALSE}
ggplot(students,aes(x=paid,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
ggplot(students,aes(x=paid,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
```

```{r message= TRUE, warning=FALSE}
ggplot(students,aes(x=famsup,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
ggplot(students,aes(x=famsup,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
```


### Comprobación de la normalidad y homogeneidad de la varianza
Para la comprobación de que los valores que toman nuestras variables cuantitativas provienen de una población distribuida normalmente, utilizaremos la prueba de normalidad de Anderson-Darling.
Así, se comprueba que para que cada prueba se obtiene un p-valor superior al nivel de significación prefijado α	$alpha$ = 0,05. Si esto se cumple, entonces se considera que la variable en cuestión sigue una distribución normal.

```{r message= TRUE, warning=FALSE}
# Tests de normalidad 
library(nortest)

# Función que aplica distintos test de homogeneidad sobre los datos de entrada
normTest <- function(data, name, alpha = 0.05) {
  ad_val = (ad.test(data)$p.value > alpha) # Anderson-Darling test
  ks_val = (ks.test(data, pnorm, mean(data), sd(data))$p.value > alpha) # Kolmogorov-Smirnov test
  sh_val = (shapiro.test(data)$p.value > alpha) # Shapiro test
  csv_val = (cvm.test(data)$p.value > alpha) # Cramer-von Mises test
  cat(name)
  cat("\t")
  cat(ad_val,ks_val,sh_val,csv_val,"\t")
  cat("\n")
}
```

```{r message= TRUE, warning=FALSE}
col.names = colnames(students)
cat("Distribucion normal: \n")
for (i in 1:ncol(students)) {
  if (is.integer(students[,i]) | is.numeric(students[,i])) {
    normTest(students[,i], col.names[i])
  }
}

```
```{r message= TRUE, warning=FALSE}
normTest(students.female[,c("score")], "score~female")
normTest(students.male[,c("score")], "score~male")
normTest(students.studytime[,c("score")], "score~studytime")
normTest(students.nostudytime[,c("score")], "score~nostudytime")
normTest(students.mayores[,c("score")], "score~mayores")
normTest(students.menores[,c("score")], "score~menores")
normTest(students.paid[,c("score")], "score~paid")
normTest(students.nopaid[,c("score")], "score~nopaid")
normTest(students.schoolsup[,c("score")], "score~schoolsup")
normTest(students.noschoolsup[,c("score")], "score~noschoolsup")
normTest(students.famsup[,c("score")], "score~famsup")
normTest(students.nofamsup[,c("score")], "score~nofamsup")
```

> Se utiliza el test de Fligner-Killeen, al no tener normalidad en los datos. 
> Se utilizaría el test Levene cuando hay normalidad en los datos.

Seguidamente, pasamos a estudiar la homogeneidad de varianzas mediante la aplicación de un test de Fligner-Killeen. 

```{r message= TRUE, warning=FALSE}
fligner.test(score ~ age, data = students)
```

```{r message= TRUE, warning=FALSE}
leveneTest(score ~ age, data = students)
```

Dado que ambas pruebas resultan en un p-valor inferior al nivel de significancia (<0.05), se rechaza la hipótesis nula de homocedasticidad y se concluye que la variable count presenta varianzas estadísticamente diferentes para los diferentes grupos de spray.

```{r message= TRUE, warning=FALSE}
fligner.test(score ~ sex, data = students)
```

```{r message= TRUE, warning=FALSE}
leveneTest(score ~ sex, data = students)
```

```{r message= TRUE, warning=FALSE}
plotNormHistogram <- function(data, name) {
    qqnorm(data,main = paste("Normal Q-Q Plot for ",name))
    qqline(data,col="red")
    hist(data, 
      main=paste("Histogram for ", name), 
      xlab=name, freq = FALSE)
}
```

```{r message= TRUE, warning=FALSE}
par(mfrow=c(2,2))
for(i in 1:ncol(students)) {
  if (is.numeric(students[,i])){
    plotNormHistogram(students[,i], colnames(students)[i])
  }
}
```
```{r message= TRUE, warning=FALSE}
par(mfrow=c(2,2))
plotNormHistogram(students.female[,c("score")], "score~sex")
plotNormHistogram(students.male[,c("score")], "score~sex")
plotNormHistogram(students.studytime[,c("score")], "score~studytime")
plotNormHistogram(students.nostudytime[,c("score")], "score~studytime")
```


## Pruebas estadísticas

Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

### Correlaciones

```{r message= TRUE, warning=FALSE}
color=diverge_hcl(length(students$calification))[rank(students$calification)]
pairs(~ G1 + G2 + G3 + score, data = students, pch = 19, cex = 0.5, lower.panel = NULL, col = color)
title("Correlación notas")
```

Luego, a la vista de estos diagramas, parece intuirse que existe una posible relación lineal entre las notas de cada trimestre.

Como ya hemos visto que estas variables no siguen una distribución normal, vamos a analizar la correlación utilizando el test de Spearman

```{r message= FALSE, warning=FALSE}
cor(x = dataStudent$G1, y = log10(dataStudent$G2), method = "spearman")
cor(x = dataStudent$G1, y = log10(dataStudent$G3), method = "spearman")
cor(x = dataStudent$G2, y = log10(dataStudent$G3), method = "spearman")
```

Vemos que para los 3 casos el grado de correlación es alto (mayor que 0,8). Pero para poder realmente considerar que existe correlación entre las variables debemos calcular la significancia

```{r message= FALSE, warning=FALSE}
# https://rpubs.com/Joaquin_AR/223351
cor.test(x = dataStudent$G1,
         y = log10(dataStudent$G2),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = dataStudent$G1,
         y = log10(dataStudent$G3),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = dataStudent$G2,
         y = log10(dataStudent$G3),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")
```

Vemos que, para los tres casos, los coeficientes de correlación son significativos puesto que p está próximo a 0 en los tres casos.


### ¿Las chicas sacan mejores notas que los chicos?


```{r message= TRUE, warning=FALSE}
t.test(students.male$score, students.female$score, alternative = "less")
```

### ¿Quien más tiempo dedica al estudio saca mejores notas?

```{r message= TRUE, warning=FALSE}
t.test(students.nostudytime$score, students.studytime$score, alternative = "less")
```

## Aquellos alumnos que van a clases particulares o reciben ayuda por parte de sus padres sacan mejores notas

### Modelo lineal

```{r message= TRUE, warning=FALSE}
smp_siz = floor(0.75*nrow(students))

set.seed(123)   # set seed to ensure you always have same random numbers generated
train_ind = sample(seq_len(nrow(students)),size = smp_siz)  # Randomly identifies the rows equal to sample size ( defined in previous instruction) from  all the rows of Smarket dataset and stores the row number in train_ind
train = students[train_ind,] #creates the training dataset with row numbers stored in train_ind
test = students[-train_ind,]  # creates the test dataset excluding the row numbers mentioned in train_ind
```

```{r message= TRUE, warning=FALSE}

# Generación de varios modelos
modelo1 <- lm(score ~ G1, data = train)
modelo2 <- lm(score ~ G1 + G2, data = train)
modelo3 <- lm(score ~ G1 + G2 + G3, data = train)
modelo4 <- lm(score ~ G1 + G3, data = train)
modelo5 <- lm(score ~ G1 + G3 + studytime, data = train)
modelo6 <- lm(score ~ studytime + sex + absences, data = train)
modelo7 <- lm(score ~ studytime + paid, data = train)
modelo8 <- lm(score ~ G1 + G3 + studytime + paid, data = train)

tabla.coeficientes <- matrix(
    c(1, summary(modelo1)$r.squared,
      2, summary(modelo2)$r.squared,
      3, summary(modelo3)$r.squared,
      4, summary(modelo4)$r.squared,
      5, summary(modelo5)$r.squared,
      6, summary(modelo6)$r.squared,
      7, summary(modelo7)$r.squared,
      8, summary(modelo8)$r.squared),
    ncol = 2, byrow = TRUE)
colnames(tabla.coeficientes) <- c("Modelo", "R^2")
tabla.coeficientes
```
```{r message= TRUE, warning=FALSE}
summary(modelo1)
```
```{r message= TRUE, warning=FALSE}
y_predict = predict(modelo8, test)
```
```{r message= TRUE, warning=FALSE}
plot(test$score, col = "green", xlab = "", ylab = "", ylim = range(0,15)) 
points(y_predict, col = "blue") 
legend("bottom", c("real", "predicted"), pch = "o", col = c("green", "blue"), trace = TRUE)
```

## Regresión logística
Imaginemos que queremos realizar un estudio para establecer un modelo que permita calcular cuál es la probabilidad de predecir que un estudiante ha recibido ayuda extraescolar (schoolsup) en función de la nota final que ha obtenido

En primer lugar vamos a representar las observaciones para poder intuir gráficamente si la varibale escogida (la nota de G3) está relacionada con la variable respuesta (obtienen ayuda escolar) y puede considerarse que es un buen predictor

```{r message= FALSE, warning=FALSE}
ggplot(data = students, aes(x = schoolsup, y = score, color = schoolsup)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")
```

Parece que hay diferencias entre la distribución de las notas para alumnos que reciban ayuda.

Ahora vamos a generar el modelo

```{r message= FALSE, warning=FALSE}
modelo <- glm(higher ~ score, data = students, family = "binomial")
summary(modelo)
```


## Conclusiones


# Recursos

Los siguientes recursos son de utilidad para la realización de la práctica:
● Calvo M., Subirats L., Pérez D. (2019). Introducción a la limpieza y análisis de los datos.
Editorial UOC.
● Megan Squire (2015). Clean Data. Packt Publishing Ltd.
● Jiawei Han, Micheine Kamber, Jian Pei (2012). Data mining: concepts and techniques.
Morgan Kaufmann.
● Jason W. Osborne (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme
Scores. Newborn and Infant Nursing Reviews; 10 (1): pp. 1527-3369.
● Peter Dalgaard (2008). Introductory statistics with R. Springer Science & Business Media.
● Wes McKinney (2012). Python for Data Analysis. O’Reilley Media, Inc.
● Tutorial de Github https://guides.github.com/activities/hello-world.


  





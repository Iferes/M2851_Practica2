---
title: "Tipología y ciclo de vida de los datos"
subtitle: "Práctica 2: Limpieza y validación de los datos"
author: 'Autores: César Fernández Domínguez, Isabel Fernández Esparza'
date: "Junio 2019"
output:
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: Practica2-header.html
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```
```{r load_libraries, include=FALSE}
library(knitr)
library(lubridate)
library(stringr)
library(dplyr)
library(ggplot2)
library(grid)
library(gridExtra)
library(plyr)
library(cowplot)
library(colorspace)
library(mlbench)
library(caret)
library(car)
library(DescTools)
```

******
# Solución
******

## Descripción del dataset

Para la realización de esta práctica se ha seleccionado un conjunto de datos relacionado con resultados académicos de estudiantes de dos colegios de Portugal disponible en el repositorio de datos *kaggle*. En concreto este conjunto de datos se ha obtenido del enlace: https://www.kaggle.com/uciml/student-alcohol-consumption

Este dataset contiene información de estudiantes de matemáticas en edad de estudios secundarios. Se puede utilizar para analizar cómo afectan a los estudiantes de secundaria sus circunstancias personales a la hora de tener voluntad de continuar con estudios de mayor nivel. Estas circunstancias personales podemos entenderlas desde el punto de vista de: nivel de estudios de los padres, trabajo de los padres, si tienen pareja o no...

Por otro lado, también se podría hacer un análisis para estudiar la relación entre el número de suspensos de los estudiantes y el nivel de estudio de los padres, la distancia de los alumnos a los colegios, cómo influye el hecho de disponer de ayuda extraescolar en los resultados escolares, el tiempo de estudio semanal, el consumo de alcohol tanto diario como semanal, el número de ausencias...

Este conjunto de datos se presenta en dos ficheros distintos, en formato CSV: student-mad.csv (asignatura de matemáticas) y student-por.csv (asignatura de portugues), uno por cada asignatura.

El objetivo de esta práctica es limpiar los datos, unificarlos y poder estimar un modelo que pueda predecir el número de suspensos de un estudiante de matemáticas atendiendo a los factores anteriormente descritos. Teniendo en cuenta que en el juego de datos tenemos información de dos colegios diferentes podemos también intentar analizar si las predicciones realizadas están también sesgadas por el colegio al que pertenezcan los alumnos o por el sexo.

A continuación, se presenta una descripción de los atributos, para cada estudiante, contenidos en los dos ficheros:

 1. school - colegio al que pertenece el alumno (binario: 'GP' - Gabriel Pereira o 'MS' - Mousinho da Silveira)
 2. sex - sexo (binario: 'F' - mujer o 'M' - hombre)
 3. age - edad (numérico: entre 15 y 22 años)
 4. address - tipo de residencia (binario: 'U' - urbana o 'R' - rural)
 5. famsize - tamaño de la familia (binario: 'LE3' - menor o igual a 3 o 'GT3' - mayor que 3)
 6. Pstatus - padres separados o no (binario: 'T' - viven juntos o 'A' - separados)
 7. Medu - nivel educativo de la madre (numérico: 0 - ninguno, 1 - educación primaria (4º grado), 2 – entre 5º a 9º grado, 3 – educación secundaria o 4 – educación superior)
 8. Fedu - nivel educativo del padre (numérico: 0 - ninguno, 1 - educación primaria (4º grado), 2 – entre 5º a 9º grado, 3 – educación secundaria o 4 – educación superior)
 9. Mjob - trabajo de la madre (nominal: 'teacher', 'health' care related, civil 'services' (p.e. administrativa o policía), 'at_home' o 'other')
10. Fjob - trabajo del padre (nominal: 'teacher', 'health' care related, civil 'services' (p.e. administrativa o policía), 'at_home' o 'other')
11. reason - razón para elegir la escuela (nominal: cerca de 'home', school 'reputation', 'course' preferencia o 'other')
12. guardian - guardian del estudiante (nominal: 'mother', 'father' o 'other')
13. traveltime - tiempo de viaje desde casa a la escuela (numérico: 1 - <15 min., 2 - 15 a 30 min., 3 - 30 min. a 1 hour, o 4 - >1 hora)
14. studytime - tiempo de estudio semanal (numérico: 1 - <2 horas, 2 - 2 a 5 horas, 3 - 5 a 10 horas, o 4 - >10 horas)
15. failures - número de asignaturas suspensas (numérico: n si 1<=n<3, en cualquier otro caso 4)
16. schoolsup - apoyo educativo adicional (binario: yes o no)
17. famsup - ayuda educativa de la familia (binario: yes o no)
18. paid - clases privadas de las asignaturas (Matemáticas o Portugues) (binario: yes o no)
19. activities - actividades extra-escolares (binario: yes o no)
20. nursery - asistió a la guardería (binario: yes o no)
21. higher - el alumno quiere realizar estudios superiores (binario: yes o no)
22. internet - el alumno tiene Internet en casa (binario: yes o no)
23. romantic - el alumno tiene pareja o no (binario: yes o no)
24. famrel - calidad de la relación familiar (numérico: desde 1 - muy mal a 5 - excelente)
25. freetime - tiempo libre después de la escuela (numérico: desde 1 - muy poco a 5 - mucho)
26. goout - el alumno sale con amigo (numérico: desde 1 - muy poco a 5 - mucho)
27. Dalc - consumo de alcohol diario (numérico: desde 1 - muy poco a 5 - mucho)
28. Walc - consumo de alcohol durante el fin de semana (numérico: desde 1 - muy poco a 5 - mucho)
29. health - estado de salud del alumno (numérico: desde 1 - muy mal a 5 - muy bueno)
30. absences - número de ausencias del alumno (numérico: desde 0 a 93)

Además de los siguientes calificaciones relacionadas con las asignaturas de matemáticas y portugues:

31. G1 - calificación primer trimestre (numérico: entre 0 a 20)
32. G2 - calificación segundo trimestre (numérico: entre 0 a 20)
33. G3 - calificación tercer trimestre (numérico: entre 0 a 20)

## Importancia y objetivos de los análisis

Según vemos en la descripción del dataset, se nos plantea la necesidad de evaluar de que forma afectan las distintas condiciones de cada estudiante para el resultado final del curso, es decir, para la nota final obtenida. Para esto, en primer lugar, necesitaremos definir alguna nueva variable que tenga en cuenta la nota obtenida durante los tres trimestres que dura el curso, como veremos en el siguiente apartado.

Son muchos los análisis y preguntas que se podrían intentar responder a partir de estos datos. Sin embargo, en nuestro caso, nos vamos centrar en las siguientes preguntas:

- ¿ Cuales son las variables que influyen más en la calificación de los estudiantes ?

- ¿ Es posible predecir cual será la calificación final de un estudiante en función de los otros atributos ? 

- ¿ Los alumnos que dedican más tiempo al estudio sacan mejores notas ?

- ¿ Aquellos alumnos que van a clases particulares o reciben ayuda por parte de sus padres sacan mejores notas ?

- En general, ¿las chicas son mejores estudiantes que los chicos?

Todas estas preguntas vamos a intentar responderlas con nuestro siguiente análisis. Como podemos adivinar, este análisis puede resultar de vital importancia tanto para el profesorado y dirección de una escuela, como para los padres de estudiantes, para así conocer si las medidas tomadas dentro y fuera de la escuela llevan a unos mejores resultados académicos.

## Integración y selección de los datos de interés a analizar.

```{r message= FALSE, warning=FALSE}
sMat=read.table("data/student-mat.csv",sep=",",header=TRUE)
sPor=read.table("data/student-por.csv",sep=",",header=TRUE)

# Según el propietario de los datos, los alumnos que están presentes en ambas asignaturas 
# pueden ser identificados por los siguientes atributos
sBoth=merge(sMat,sPor,by=c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))

# school, sex, age, address, famsize, Pstatus, Medu, Fedu, Mjob, Fjob, reason, nursery, internet
# traveltime, studytime, failures, schoolsup, famsup, paid, activities, higher, romantic, famrel
# freetime, goout, Dalc, Walc, health, absences, subject
```

Ambos ficheros de datos de estudiantes contienen `r dim(sPor)[2]` atributos (columnas). El fichero de estudiantes de la asignatura de portugues contiene `r dim(sPor)[1]` estudiantes y, el de la asignatura de matemáticas `r dim(sMat)[1]` estudiantes. Si mezclamos ambos ficheros para obtener los alumnos que están en ambas asignaturas obtenemos un total de `r dim(sBoth)[1]` estudiantes.

Identificamos cada estudiante mediante los atributos indicados por el propietario del juego de datos. Generamos un identificador con la concatenación de estos atributos para cada estudiante. Después, en otro paso, convertiremos este identificador en un valor numérico que identifique a cada estudiante.

```{r message= FALSE, warning=FALSE}
sMat$id = paste(sMat$school,sMat$sex,sMat$age,sMat$address,sMat$famsize,sMat$Pstatus,sMat$Medu,sMat$Fedu,sMat$Mjob,sMat$Fjob,sMat$reason,sMat$nursery,sMat$internet, sep="-")
sPor$id = paste(sPor$school,sPor$sex,sPor$age,sPor$address,sPor$famsize,sPor$Pstatus,sPor$Medu,sPor$Fedu,sPor$Mjob,sPor$Fjob,sPor$reason,sPor$nursery,sPor$internet, sep="-")
```

Creamos una variable "score" que contendrá la media de las tres notas de los tres trimestres por cada alumno y asignatura. Luego, a partir de esta variable, creamos una variable categórica que exprese si un alumno ha aprobado o suspendido la asignatura. Además, creamos una nueva variable categórica que expresará la nota obtenida según la clasificación de cinco niveles utilizada en los grados Erasmus.
 
```{r message= FALSE, warning=FALSE}
sMat$score = rowMeans(subset(sMat, select = c(G1, G2, G3)), na.rm = TRUE)
sMat$mark<-sMat$score
sMat$mark[sMat$score<10] <- "fail"
sMat$mark[sMat$score>=10] <- "pass"
sMat$mark <- as.factor(sMat$mark)
sMat$calification <- sMat$score
sMat$calification[(sMat$score<=20) & (sMat$score>=16)] <- "A"
sMat$calification[(sMat$score<16) & (sMat$score>=14)] <- "B"
sMat$calification[sMat$score<14 & sMat$score>=12] <- "C"
sMat$calification[sMat$score<12 & sMat$score>=10] <- "D"
sMat$calification[sMat$score<10] <- "F"
sMat$calification <- as.factor(sMat$calification)

sPor$score = rowMeans(subset(sPor, select = c(G1, G2, G3)), na.rm = TRUE)
sPor$mark<-sPor$score
sPor$mark[sPor$score<10] <- "fail"
sPor$mark[sPor$score>=10] <- "pass"
sPor$mark <- as.factor(sPor$mark)
sPor$calification <- sPor$score
sPor$calification[(sPor$score<=20) & (sPor$score>=16)] <- "A"
sPor$calification[(sPor$score<16) & (sPor$score>=14)] <- "B"
sPor$calification[sPor$score<14 & sPor$score>=12] <- "C"
sPor$calification[sPor$score<12 & sPor$score>=10] <- "D"
sPor$calification[sPor$score<10] <- "F"
sPor$calification <- as.factor(sPor$calification)
```

Vamos a crear un par de variables binarias nuevas para después unir los dos ficheros en un solo dataset:

```{r message= FALSE, warning=FALSE}

sMat$subject = 'Math'
sPor$subject = 'Portuguese'
students = rbind(sMat,sPor)
students$subject = as.factor(students$subject)
```

Ahora, a partir del identificador que anteriormente habiamos creado para cada estudiante, lo transformamos en un identificador numérico simple.

```{r message= FALSE, warning=FALSE}
students = transform(students, id=as.numeric(factor(id)))
students$id = as.factor(students$id)
```

Ahora tenemos un dataset con `r dim(students)[1]` instancias y `r dim(students)[2]` atributos para un total de `r length(unique(students$id))` estudiantes de ambas asignaturas.

Así, nuestro dataset nos queda como:
```{r message= TRUE, warning=FALSE}
# Resumen
glimpse(students)
```
```{r message= FALSE, warning=FALSE, include=FALSE}
nro_factors = 0
nro_numeric = 0
for (i in 1:ncol(students)) {
  if (is.factor(students[,i])) nro_factors=nro_factors+1 else nro_numeric=nro_numeric+1
}
```
Tenemos un total de `r nro_numeric` variables numéricas y `r nro_factors` categóricas.

A continuación, mostramos las estadísticas básicas para cada variable de nuestro dataset final:
```{r message= TRUE, warning=FALSE}
# Estadísticas básicas
summary(students)
```
Vemos que tenemos muchos más alumnos del colegio Gabriel Pereira (`r dim(students[students$school == "GP",])[1]`) que del Mousinho da Silveira (`r dim(students[students$school == "MS",])[1]`). Un total de `r dim(students[students$mark == "pass",])[1]` aprobados frente a `r dim(students[students$mark == "fail",])[1]` suspensos.

## Limpieza de los datos

#### ¿Los datos tienen contienen ceros o elementos vacíos? ¿Cómo gestionaríamos cada uno de estos casos?

Primero vamos a comprobar si nuestro juego de datos contiene valores nulos.

```{r message= TRUE, warning=FALSE}
# Con datos nulos
colSums(is.na(students))
```

vemos que no existen valores vacíos.

Ahora vamos a comprobar si existen valores vacíos

```{r message= TRUE, warning=FALSE}
# Con datos ""
colSums(students=="")
```
Se observa que tampoco existen valores vacíos.

Luego como no existen nulos o elementos vacios no tenemos que hacer nada a este respecto.

Comprobamos, también, la existencia de valores cero. 

```{r message= TRUE, warning=FALSE}
colSums(students==0)
```

En este caso, vemos que algunos atributos contienen valores cero. Sin embargo, estos valores corresponden a variables numéricas y  comprobamos la validez los mismos.

Por último, visualizamos el número de valores únicos por cada atributo, comprobando su correspondencia con los datos.

```{r message= TRUE, warning=FALSE}
# Valores unicos
apply(students,2, function(x) length(unique(x)))
```

#### Identificación y tratamiento de valores extremos.

Los valores extremos o outliers son aquellas observaciones que están fuera de 1,5*IQR, donde IQR es la diferencia entre los cuartiles 75 y 25. Para buscar los outliers en nuestro juego de datos recorremos el dataset para encontrar todas aquellas variables numéricas y hacemos la representación gráfica de los outliers de cada una de ellas.

```{r message= TRUE, warning=FALSE}
par(mfrow=c(1,3))
for(i in 1:ncol(students)) {
  if (is.numeric(students[,i])){
    boxplot(students[,i], main = colnames(students)[i], width = 100)
  }
}
```


Vamos a analizar los diferentes outliers para cada una de las variables numéricas:

Hemos encontrado información interesante para el tratamiento de los outliers en la siguiente dirección web

https://www.ugr.es/~fmocan/MATERIALES%20DOCTORADO/Tratamiento%20de%20outliers%20y%20missing.pdf

Variable Age: Vemos que hay un outlier en el valor 22. En este caso consideramos que este valor no debería eliminarse y deberia tratarse como uno más, probablemente el hecho de que haya alumnos de 22 años en el mismos curso que alumnos de 18 años estará relacionado con algunas de las variables que queremos analizar, principalmente las notas.

Variables Medu y Fedu: No tienen valores extremos.

Variable traveltime: Vemos que hay un outlier en el valor 4. Es decir, se dan casos extremos en los que los alumnos tardan 4 horas en llegar al colegio. Vamos a ver cuántas veces se da este valor en nuestra muestra

```{r message= FALSE, warning=FALSE}
length(boxplot.stats(students[,c("traveltime")])$out)
```

Vemos que tenemos 24 alumnos que tardan más de 3 horas en ir al colegio. El tiempo que tardan los alumnos en llegar al colegio no es una varaiable sobre la que queramos realizar hipótesis, como además, el número total de outliers para este atributo es 24, esto representa el 2% de la muestra así que los eliminamos.

```{r message= FALSE, warning=FALSE}
students = students[students$traveltime<=3,]
```

La variable tiempo de estudio studytime vemos que también tiene un outlier en el valor 4. El tiempo de estudio de los alumnos sí que pensamos que es una variable que puede influir en los resultados finales y es una de los atributos que vamos a tener en cuenta en nuestros análisis. No consideramos que el 4 sea un outlier que haya ni que eliminar ni tratar puesto que es un valor aceptable para nuestro estudio, luego con este outlier no hacemos nada.

Lo mismo pasa con la variable que mide los suspensos, los valores que aparecen representados como outliers son precisamente los valores que pueden ser relevantes para nuestro estudio, luego no hacemos nada con ellos 

La variable freetime tiene un outlier en el valor 1, vamos a ver cuántos estudiantes cumplen esta condición. 

```{r message= FALSE, warning=FALSE}
students[students$freetime==1,]
```

Son 64 alumnos que tienen muy poco tiempo libre entre semana. Puesto que este valor está relacionado con el tiempo de estudio semanal y con las ayudas extrasescolares que puedan recibir los alumnos decidimos mantenerlos también.

Variable famrel: Tenemos outliers en 1 y 2. Estos valores miden la calidad de las relaciones familiares, entendiendo que estos valores se han obtenido a través de una encuesta a los propios alumnos.  El valor de 1 es tan bajo que pensamos que puede deberse a una manipulación por parte de los alumnos en las respuestas. Consideramos que una forma de tratar estos outliers es reemplazarlos por la moda (más repetida). Los valores de 2 los dejaremos como están puesto que no nos parece que puedan considrarse como outliers. Para calcular la moda utilizamos una tabla de frecuencia para contar el número de veces que se repite cada valor:

```{r message= FALSE, warning=FALSE}
table(students$famrel)
```

Vemos que el valor más repetido es el 4, luego sustituimos aquellas columnas que tengan el valor 1 en la columna famrel por 4

```{r message= FALSE, warning=FALSE}
students$famrel[students$famrel == 1] <- 4
```

En el caso del consumo diario de alcohol, tenemos un outlier en los valores 4 y 5. Sin embargo no tenemos estos outliers en el consumo del fin de semana. Pensamos por tanto que el hecho de que alumnos consuman mucho alcohol durante los días de diario puede estar relacionado con las notas que obtengan, así que vamos a dejar estos valores.

```{r message= FALSE, warning=FALSE}
length(boxplot.stats(students[,c("Dalc")])$out)
```

Para el caso de las ausencias, nos interesa saber cuántos outliers tenemos y qué valores toman para poder analizar cómo tratarlos.

```{r message= FALSE, warning=FALSE}
length(boxplot.stats(students[,c("absences")])$out)
boxplot.stats(students[,c("absences")])$out
students[students$absences>=40,]
```

A la vista de los resultados vemos que tenemos 54 outliers en las ausencias, y que los valores que toman en estos outliers son  16 16 25 54 18 26 20 18 16 16 56 24 18 28 22 16 18 20 16 21 75 22 30 19 20 38 18 20 22 40 23 16 17 16 16 24 22 16 32 
Nos parece que los valores que están en un intervalo de (10,30) son admisibles, sin embargo, vemos que hay valores que pasan de 40 que podrían eliminarse.

En total, vamos a contar cuántos datos tenemos para ausencias mayores o iguales que 40

```{r message= FALSE, warning=FALSE}
students[students$absences>=40,]
```

Vemos que tenemos 4 valores, luego decidimos eliminarlos de nuestro objeto de estudio

```{r message= FALSE, warning=FALSE}
students = students[students$absences<40,]
glimpse(students)
```

Las columnas relativas a las notas van a ser principalmente las que sean objeto de estudio. Tenemos outliers en notas que son perfectamente posibles, luego no vamos a eliminarlo puesto que pensamos que estos valores afectarán a los estudios e hipótesis que queramos estudiar.


## Análisis de los datos
  
### Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).

En este apartado, vamos a realizar una selección de atributos que podrán ser de utilidad para los análisis posteriores en función de los objetivos iniciales. 

Por ejemplo, podemos discreminar nuestros datos según su género: hombre o mujer (male o female):

```{r message= TRUE, warning=FALSE}
# Agrupación por sexo de los estudiantes
students.male <- students[students$sex == "M",]
students.female <- students[students$sex == "F",]
```

Esta agrupación nos podrá servir para intentar responder a la pregunta de si las chicas son, en general, mejores estudiantes que los chicos.

Por otra parte, también podemos agrupar nuestros datos dependiendo de si reciben algún tipo de ayuda en el estudio, por ejemplo: mediante clases particulares, ayuda familiar o soporte extra en el colegio. 

```{r message= TRUE, warning=FALSE}
# Agrupación por si reciben clases particules pagadas o no
students.paid <- students[students$paid == "yes",]
students.nopaid <- students[students$paid == "no",]

# Agrupación por si reciben soporte por parte de la familia
students.famsup <- students[students$famsup == "yes",]
students.nofamsup <- students[students$famsup == "no",]

# Agrupación por si reciben ayuda extra escolar
students.schoolsup <- students[students$schoolsup == "yes",]
students.noschoolsup <- students[students$schoolsup == "no",]
```

También vamos a realizar una agrupación de los estudiantes dependiendo del número de horas que dediquen semanalmente al estudio. En este caso, agrupamos por aquellos que dedican 3 o más horas semanalmente al estudio y aquellos que dedican menos de 3 horas semanales.

```{r message= TRUE, warning=FALSE}
# Agrupación por tiempo dedicado al estudio
students.studytime <- students[students$studytime >= 3,]
students.nostudytime <- students[students$studytime < 3,]
```

Como vemos, resulta muy sencillo realizar la agrupación de nuestros datos dependiendo de distintas variables. Así, por ejemplo, también podremos disociar nuestros datos dependiendo del nivel de estudios de los padres.

```{r message= TRUE, warning=FALSE}
# Agrupación por estudios de los padres
students.parentedu <- students[(students$Medu >= 3) | (students$Fedu >= 3),]
students.parentnoedu <- students[(students$Medu < 3) & (students$Fedu < 3),]
```
o, agrupando por edad de los estudiantes:

```{r message= TRUE, warning=FALSE}
# Agrupación por edad
students.mayores <- students[students$age >= 16,]
students.menores <- students[students$age < 16,]
```

Estas agrupaciones de los datos de nuestro dataset original no serán todas utilizada en los siguientes análisis. O, como en la siguiente sección, esta agrupación será realizada de forma gráfica.

### Análisis visual

En este apartado vamos a realizar un análisis gráfico básico de nuestro dataset respecto a las variables objeto de nuestro estudio.

En primer lugar, vemos cual es la distribución de notas de los estudiantes entre chicos y chicas.

```{r message= TRUE, warning=FALSE}
fig1 = ggplot(students,aes(x=sex,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")
fig2 = ggplot(students,aes(x=sex,fill=calification))+geom_bar()+ylab("Frecuencia")
grid.arrange(fig1, fig2, ncol=2)
```

Vemos como, en porcentaje, ambos grupos presentan notas similares. Quizá podemos apreciar un mayor porcentaje de aprobados en las chicas que en los chicos, pero nada significativo. También vemos que el número de muestras de chicas es superior al de chicos.

En las siguientes figuras, mostramos la calificación respecto a las horas de estudio semanales dedicadas por cada estudiante:

```{r message= TRUE, warning=FALSE}
fig1 = ggplot(students,aes(x=studytime,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")
fig2 = ggplot(students,aes(x=studytime,fill=calification))+geom_bar()+ylab("Frecuencia")
grid.arrange(fig1, fig2, ncol=2)
```

Vemos como, a medida que se aumenta el número de horas semanales de estudio, aumenta también la probabilidad de obtener una nota alta. Vemos como, a pesar de dedicar más de 4 horas semanales al estudio, el porcentaje de suspensos es mayor que aquellos que solamente dedican 3 horas semanales. Lo cual confirma lo que siempre se dice que con dedicar un poco de tiempo diariamente al estudio es suficiente para sacar buenas notas. También observamos que el número de alumnos que dedican más horas al estudio es mucho menor que aquellos que dedican más horas.

Si diferenciamos entre chicos y chicas:

```{r message= TRUE, warning=FALSE}
fig1 = ggplot(students,aes(x=studytime,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
fig2 = ggplot(students,aes(x=studytime,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
grid.arrange(fig1, fig2, ncol=2)
```

Vemos como en los chicos es significativo el porcentaje de suspensos en aquellos alumnos que dedican 4 horas o más semanales al estudio. Casi equiparable a aquellos que practicamente no dedican tiempo al estudio. En las chicas se ve una mayor progresión en mejoría de las notas a medida que se aumenta el tiempo de estudio. En las chicas, la gran mayoría afirma dedicar solamente 2 horas al estudio semanalmente.

Ahora vamos a visualizar cual es la influencia de la ayuda extra sobre las calificaciones de los estudiantes.

En primer lugar, visualizamos como influye el hecho de que los alumnos reciban ayuda extra por parte del colegio.

```{r message= TRUE, warning=FALSE}
fig1 = ggplot(students,aes(x=schoolsup,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")
fig2 = ggplot(students,aes(x=schoolsup,fill=calification))+geom_bar()+ylab("Frecuencia")
grid.arrange(fig1, fig2, ncol=2)
```

En primer lugar, vemos que el número de alumnos que recibe ayuda extra es muy inferior a los que no la reciben. Seguramente esta ayuda solamente sea dada a aquellos alumnos que, por diversas razones, se vea que necesitan un soporte especial por parte del colegio (en general, mal estudiante). Vemos, que, a pesar de recibir ayuda extra en el colegio, practicamente el 70% de estos estudiantes suspende. Sí hay un pequeño porcentaje que aprueba con buena cualificación.

Diferenciando entre chicos y chicas:

```{r message= TRUE, warning=FALSE}
fig1 = ggplot(students,aes(x=schoolsup,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
fig2 = ggplot(students,aes(x=schoolsup,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
grid.arrange(fig1, fig2, ncol=2)
```

Apreciamos que el hecho de recibir ayuda extra por parte del colegio, es mejor aprovechado por las chicas que por los chicos. En el caso de los chicos, unicamente aprueba alrededor del 20% de los chicos que recibe soporte extra por parte del colegio.

Analizando según vayan a clases particules o no, tenemos:

```{r message= TRUE, warning=FALSE}
fig1 = ggplot(students,aes(x=paid,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")
fig2 = ggplot(students,aes(x=paid,fill=calification))+geom_bar()+ylab("Frecuencia")
grid.arrange(fig1, fig2, ncol=2)
```

En estas gráficas vemos como un porcentaje pequeño (alrededor del 20%) de los estudiantes recibe clases particulares. Vemos que el porcentaje de aprobados es mayor en aquellos que van a clases particulares, pero no significativamente. Además es mayor el porcentaje de aprobados con nota más alta en aquellos alumnos que no reciben clases particulares. Posiblemente, porque el hecho de recibir clases particules se perciba más en estudiantes que necesitan un pequeño soporte extra.

De igual forma que en otros casos, si diferenciamos entre chicos y chicas, tenemos:

```{r message= TRUE, warning=FALSE}
fig1 = ggplot(students,aes(x=paid,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
fig2 = ggplot(students,aes(x=paid,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
grid.arrange(fig1, fig2, ncol=2)
```

En este caso no se aprecian diferencias significativas entre chicos y chicas. Quizá, podemos observar que, la mejora, en porcentage, entre aquellos estudiantes que van a clases particulares y los que no, es mayor en las chicas.

Por último, visualizamos la distribución de las calificaciones de los estudiantes dependiendo de si reciben ayuda por parte de su familia o no:

```{r message= TRUE, warning=FALSE}
fig1 = ggplot(students,aes(x=famsup,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")
fig2 = ggplot(students,aes(x=famsup,fill=calification))+geom_bar()+ylab("Frecuencia")
grid.arrange(fig1, fig2, ncol=2)
```

En este caso, es resaltable que el número de estudiantes que recibe ayuda de su familia es bastante mayor de los que no la reciben. Sin embargo, los resultados académicos con equipables (gráfica de porcentajes).

Diferenciando entre chicos y chicas:

```{r message= TRUE, warning=FALSE}
fig1 = ggplot(students,aes(x=famsup,fill=calification))+geom_bar(position="fill")+ylab("Porcentaje")+facet_wrap(~sex )
fig2 = ggplot(students,aes(x=famsup,fill=calification))+geom_bar()+ylab("Frecuencia")+facet_wrap(~sex )
grid.arrange(fig1, fig2, ncol=2)
```

Son casi el doble las chicas reciben ayuda de sus familiares de las que no. En los chicos está más equilibrado. En cuando a los resultados académicos, vemos una ligera mejoría, ligerísima, entre las chicas que reciben ayuda y las que no. 

### Comprobación de la normalidad y homogeneidad de la varianza
Para la comprobación de que los valores que toman nuestras variables cuantitativas provienen de una población distribuida normalmente, utilizaremos la prueba de normalidad de Anderson-Darling.
Así, se comprueba que para que cada prueba se obtiene un p-valor superior al nivel de significación prefijado α	$alpha$ = 0,05. Si esto se cumple, entonces se considera que la variable en cuestión sigue una distribución normal.

```{r message= TRUE, warning=FALSE}
# Tests de normalidad 
library(nortest)

# Función que aplica distintos test de homogeneidad sobre los datos de entrada
normTest <- function(data, name, alpha = 0.05) {
  ad_val = (ad.test(data)$p.value > alpha) # Anderson-Darling test
  ks_val = (ks.test(data, pnorm, mean(data), sd(data))$p.value > alpha) # Kolmogorov-Smirnov test
  sh_val = (shapiro.test(data)$p.value > alpha) # Shapiro test
  csv_val = (cvm.test(data)$p.value > alpha) # Cramer-von Mises test
  cat(name)
  cat("\t")
  cat(ad_val,ks_val,sh_val,csv_val,"\t")
  cat("\n")
}
```

```{r message= TRUE, warning=FALSE}
col.names = colnames(students)
cat("Distribucion normal: \n")
for (i in 1:ncol(students)) {
  if (is.integer(students[,i]) | is.numeric(students[,i])) {
    normTest(students[,i], col.names[i])
  }
}

```

Luego a la vista de los resultados obtenidos en los diferentes tests de normalidad, vemos que ninguna de las variables numéricas que tenemos en nuestro juego de datos sigue una distribución normal con respecto al conjunto total de los datos.

Ahora vamos a ver si estas variables numéricas siguen una distribución normal en cada uno de los grupos que hemos separado para realizar nuestro análisis. Es decir, vamos a ver si:

Hemos visto que las notas registradas no siguen una distrubución normal para el conjunto total de los datos pero, seguirán una distribución normal en el conjunto de hombres o de mujeres? ¿Y en el caso de que el tiempo de estudio sea de más de 3 horas o de menos? ¿Y de los alumnos mayores de 16 años o menores? ¿Y si separamos los datos entre alumnos que reciben clases particulares pagadas y no? ¿Y si reciben ayuda extraescolar de familia o en el colegio?

```{r message= TRUE, warning=FALSE}
normTest(students.female[,c("score")], "score~female")
normTest(students.male[,c("score")], "score~male")
normTest(students.studytime[,c("score")], "score~studytime")
normTest(students.nostudytime[,c("score")], "score~nostudytime")
normTest(students.mayores[,c("score")], "score~mayores")
normTest(students.menores[,c("score")], "score~menores")
normTest(students.paid[,c("score")], "score~paid")
normTest(students.nopaid[,c("score")], "score~nopaid")
normTest(students.schoolsup[,c("score")], "score~schoolsup")
normTest(students.noschoolsup[,c("score")], "score~noschoolsup")
normTest(students.famsup[,c("score")], "score~famsup")
normTest(students.nofamsup[,c("score")], "score~nofamsup")
```

Según los resultados obtenidos vemos que, para los alumnos menores de 16 años, las notas medias sí siguen una distribución normal, y para el caso de los que reciben clases particulares pagadas también así como para aquellos que reciben apoyo educativo adicional . Para el caso de las alumnas femeninas,y de los grupos que reciben o no reciben ayuda extraescolar familiar, el test de Kolmogorov sí indica que las variables de notas medias siguen una distribución normal

> Se utiliza el test de Fligner-Killeen, al no tener normalidad en los datos. 
> Se utilizaría el test Levene cuando hay normalidad en los datos.

Vamos a estudiar ahora la homogeneidad de la varianza para los diferentes grupos que queremos analizar. En primer lugar vamos a analizar la homocedasticidad entre niños y niñas. Vimos en el apartado anterior que esta variable no sigue una distribución normal para estos grupos, luego para realizar nuestro análisis utilizaremos el test de Fligner-Killeen.


```{r message= TRUE, warning=FALSE}
fligner.test(score ~ sex, data = students)
```

Vemos, por tanto, que el valor de p obtenido (p-value) es mayor que 0,05 luego esto indica que no se observa diferencia significativa entre las varianzas por grupos de sexo.

Vamos a aplicar el test de Levene para ver que resultado obtenemos en este caso:


```{r message= TRUE, warning=FALSE}
leveneTest(studytime ~ sex, data = students)
```

Para este caso también se cumpliría que el valor de p es mayor de 0,05 luego también indicaría que no existe diferencia significativa entre las varianzas

Veamos ahora cómo se distribuye la varianza para la media escolar entre los grupos de alumnos que reciben clases privadas de las asignaturas. Nuevamente, como estos valores no siguen una distribución normal, utilizaremos el test de Fligner-Killeen

```{r message= TRUE, warning=FALSE}
fligner.test(score ~ paid, data = students)
```


Nuevamente, vemos que el valor de p es mayor de 0.05, luego podemos concluir que las varianzas están homogéneamente distrubuidas.

Si aplicamos es test de Levene

```{r message= TRUE, warning=FALSE}
leveneTest(score ~ paid, data = students)

```

Vemos también el mismo resultado

Si ahora analizamos las distribuciones atendiendo a si reciben clases estraescolares o ayudas de sus padres, vamos a ver qué obtenemos, nuevamente aplicando el test de Fligner-Killeen por la falta de normalidad en nuestros datos.

```{r message= TRUE, warning=FALSE}
fligner.test(score ~ schoolsup, data = students)
```

En este caso vemos que el valor de p obtenido es menor que 0,05 luego vemos que la variable score (que recoge las medias de todas las notas obtenidas) presenta varianzas estadísticamente diferentes para los grupos de alumnos que reciben ayuda extraescolar o no en el colegio.

Vamos a ver qué resultados obtenemos para este caso utilizando el test de Levene

```{r message= TRUE, warning=FALSE}
leveneTest(score ~ schoolsup, data = students)
```

Nuevamente el valor es menor que 0.05

Analicemos ahora cómo se distribuye la varianza de las notas medias para los grupos de alumnos que reciben ayuda suplementaria en casa. Nuevamente, usamos el test de Fligner-Killeen

```{r message= TRUE, warning=FALSE}
fligner.test(score ~ famsup, data = students)
```

En este caso, se observa que el valor de p (p-value) es mayor de 0,05 luego podemos concluir que las varianzas son homogéneas para estos grupos de estudiantes

Analicemos cómo se distribuye la varianza de las notas medias por los diferentes grupos de edad, entre los alumnos menores de 16 y los mayores de 16

```{r message= TRUE, warning=FALSE}
a <- students[students$age < 16,"score"]
b <- students[students$age >= 16,"score"]
fligner.test(x = list(a,b))
```

El valor de p que obtenemos es menor que 0.05 lyego rechazamos la hipótesis de homocedasticidad y concluimos que la variable score tiene varianzas estadísticamente diferentes para los alumnos menores de 16 y los mayores de 16.

Por último estudiaremos la distribución de la varianza para los grupos de alumnos que estudian más o menos de 3 horas.

```{r message= TRUE, warning=FALSE}
a <- students[students$studytime < 3,"score"]
b <- students[students$studytime >= 3,"score"]
fligner.test(x = list(a,b))
```

El valor de p es mayor de 0.05 luego podemos concluir que sí existe homogeneidad de la varianza

Vamos a representar los histogramas de estas variables

```{r message= TRUE, warning=FALSE}
plotNormHistogram <- function(data, name) {
    qqnorm(data,main = paste("Normal Q-Q Plot for ",name))
    qqline(data,col="red")
    hist(data, 
      main=paste("Histogram for ", name), 
      xlab=name, freq = FALSE)
}
```

```{r message= TRUE, warning=FALSE}
par(mfrow=c(2,2))
for(i in 1:ncol(students)) {
  if (is.numeric(students[,i])){
    plotNormHistogram(students[,i], colnames(students)[i])
  }
}
```
```{r message= TRUE, warning=FALSE}
par(mfrow=c(2,2))
plotNormHistogram(students.female[,c("score")], "score~sex")
plotNormHistogram(students.male[,c("score")], "score~sex")
plotNormHistogram(students.studytime[,c("score")], "score~studytime")
plotNormHistogram(students.nostudytime[,c("score")], "score~studytime")
plotNormHistogram(students.mayores[,c("score")], "score~mayores")
plotNormHistogram(students.menores[,c("score")], "score~menores")
```


## Pruebas estadísticas

Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

### Correlaciones

```{r message= TRUE, warning=FALSE}
color=diverge_hcl(length(students$calification))[rank(students$calification)]
pairs(~ G1 + G2 + G3 + score, data = students, pch = 19, cex = 0.5, lower.panel = NULL, col = color)
title("Correlación notas")
```

Luego, a la vista de estos diagramas, parece intuirse que existe una posible relación lineal entre las notas de cada trimestre.

Como ya hemos visto que estas variables no siguen una distribución normal, vamos a analizar la correlación utilizando el test de Spearman

```{r message= FALSE, warning=FALSE}
cor(x = students$G1, y = log10(students$G2), method = "spearman")
cor(x = students$G1, y = log10(students$G3), method = "spearman")
cor(x = students$G1, y = log10(students$score), method = "spearman")
cor(x = students$G2, y = log10(students$G3), method = "spearman")
cor(x = students$G2, y = log10(students$score), method = "spearman")
cor(x = students$G3, y = log10(students$score), method = "spearman")
```

Vemos que para los 4 casos el grado de correlación es alto (mayor que 0,8). Pero para poder realmente considerar que existe correlación entre las variables debemos calcular la significancia

```{r message= FALSE, warning=FALSE}
# https://rpubs.com/Joaquin_AR/223351
cor.test(x = students$G1,
         y = log10(students$G2),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = students$G1,
         y = log10(students$G3),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = students$G1,
         y = log10(students$score),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = students$G2,
         y = log10(students$G3),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = students$G2,
         y = log10(students$score),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")

cor.test(x = students$G3,
         y = log10(students$score),
         alternative = "two.sided",
         conf.level  = 0.95,
         method      = "spearman")
```

Vemos que, para todos los casos, los coeficientes de correlación son significativos puesto que p está próximo a 0 en los tres casos.

### Pruebas de hipótesis

En esta sección, vamos a intentar responder a algunas de las preguntas que se plantearon en los objetivos iniciales mediante una prueba de hipótesis. Puesto que para las variables sobre las que vamos a realizar esta prueba hemos visto que no siguen los criterios de normalidad y homocedasticidad, exigidos para poder aplicar la prueba de t-student, vamos a aplicar pruebas no paramétricas como Wilcoxon (cuando se comparen datos dependientes) o Mann-Whitney (cuando los grupos de datos sean independientes). Podemos aplicar esta prueba utilizando la función "*wilcox.text*".

#### ¿Las chicas sacan mejores notas que los chicos?

En la primera pregunta que nos planteabamos, de si las chicas sacan mejores notas que los chicos, la hipótesis consiste en considerar si las calificaciones obtenidas por las chicas y los chicos tienen idéntica distribución.

```{r message= TRUE, warning=FALSE}
wilcox.test(score ~ sex, data = students)
```

En este caso, vemos que p-value > 0.05, por lo tanto debemos decir que las calificaciones obtenidas por los chicas son estadísticamente comparables a las obtenidas por los chicos. Por lo tanto, no podemos decir que las chicas sacan mejores notas que los chicos.

#### ¿Quien más tiempo dedica al estudio saca mejores notas?

En esta ocasión queremos comparar los grupos de estudiantes que estudian durante bastante tiempo semanal y los que dedican menos tiempo al estudio.

Para esto, lo primero que vamos a hacer es crear una nueva variable categórica que nos permita distinguir entre los dos grupos mencionados arriba.

```{r message= TRUE, warning=FALSE}
students$studytime2g<-students$studytime
students$studytime2g[students$studytime<3] <- "few"
students$studytime2g[students$studytime>=3] <- "many"
students$studytime2g <- as.factor(students$studytime2g)
```

Aplicando, ahora, la prueba sobre estos grupos de estudiantes obtenemos:

```{r message= TRUE, warning=FALSE}
wilcox.test(score ~ studytime2g, data = students)
```
El valor de p-value obtenido es menor de 0.05. Por lo tanto, concluimos que ambos grupos de estudiantes presentan distribuiones muy distintas. Es decir, existe diferencias significativas en la notas obtenidas entre los estudiantes que dedican muchas horas al estudio y las que dedican pocas.

Si ahora comparamos entre los grupos de estudiantes que dedican 3 horas semanales y los que dedican 4 o más, vemos que el valor p-value es igual a 0.683. Es decir, es mayor que 0.05. Por lo tanto, siguen una misma distribución.

```{r message= TRUE, warning=FALSE}
wilcox.test(score ~ studytime, data = students, subset = studytime %in% c(3, 4))
```

#### ¿Aquellos alumnos que van a clases particulares o reciben ayuda por parte de sus padres sacan mejores notas?

Por último, vamos a aplicar la prueba de hipotésis para intentar responder a la otra pregunta que nos habíamos planteado: ¿hay diferencias en las calificaciones según los estudiantes reciban ayuda extra o no?

La primera prueba la aplicamos sobre los estudiantes que van a clases particulares y los que no:

```{r message= TRUE, warning=FALSE}
wilcox.test(score ~ paid, data = students)
```

En este caso, el valor de *p* es mayor, aunque por muy poco, a 0.05. Por lo tanto, diremos que no existe diferencia estadística, en las notas, entre los alumnos que van a clases particulares y los que no.    

En lo que se refiere a la si reciben ayuda extra por parte del colegio o no, tenemos que...

```{r message= TRUE, warning=FALSE}
wilcox.test(score ~ schoolsup, data = students)
```

... existe diferencia significativa entre los alumnos que reciben ayuda extra y los que no (tal y como también vimos en el análisis visual de los datos).

Por último, aplicaremos esta prueba también sobre los grupos de estudiantes que son ayudados por su familia en casa y los que no.

```{r message= TRUE, warning=FALSE}
wilcox.test(score ~ famsup, data = students)
```

Según el resultado obtenido, no podemos decir que exista diferencia significativa, en las notas finales, entre los estudiantes que son ayudados por su familia en casa y los que no.

### Modelo lineal

Tal y como hemos visto, existe una fuerte correlación entre las distintas variables que se refieren a las calificaciones y la nota final. Por lo tanto, vamos a utilizar estas variables para obtener un modelo lineal que nos permita predecir las notas de los estudiantes a partir de algunas de las otras variables.

En primer lugar, dividiremos nuestros datos entre un grupo de entrenamiento y otro de prueba, que nos permitirá evaluar la precisión de las predicciones realizadas por nuestro modelo.

```{r message= TRUE, warning=FALSE}
sample_size = floor(0.90*nrow(students)) # 90% train - 10% test
train_idx = sample(seq_len(nrow(students)),size = sample_size) 
train = students[train_idx,] 
test = students[-train_idx,]
```

Definiremos varios modelos utilizando distintas variables relacionadas con la calificación final (*score*) para finalmente elegir aquel que mejores resultados nos dé.

```{r message= TRUE, warning=FALSE}

# Generación de varios modelos
modelo1 <- lm(score ~ G1 + G2 + G3, data = train)
modelo2 <- lm(score ~ G1 + G2, data = train)
modelo3 <- lm(score ~ G1 + G3, data = train)
modelo4 <- lm(score ~ G1, data = train)
modelo5 <- lm(score ~ G2, data = train)
modelo6 <- lm(score ~ G3, data = train)
modelo7 <- lm(score ~ G1 + G3 + studytime, data = train)
modelo8 <- lm(score ~ G2 + studytime + schoolsup, data = train)
modelo9 <- lm(score ~ studytime + sex + absences, data = train)
modelo10 <- lm(score ~ studytime + paid, data = train)

tabla.coeficientes <- matrix(
    c(1, summary(modelo1)$r.squared,
      2, summary(modelo2)$r.squared,
      3, summary(modelo3)$r.squared,
      4, summary(modelo4)$r.squared,
      5, summary(modelo5)$r.squared,
      6, summary(modelo6)$r.squared,
      7, summary(modelo7)$r.squared,
      8, summary(modelo8)$r.squared,
      9, summary(modelo9)$r.squared,
      10, summary(modelo10)$r.squared),
    ncol = 2, byrow = TRUE)
colnames(tabla.coeficientes) <- c("Modelo", "R^2")
tabla.coeficientes
```

Esta claro, según confirmamos por los resultados obtenidos, que si utilizamos las notas de los tres trimestres para predecir la calificación final el resultado será exacto, ya que esta nota se obtiene a partir de un calculo directo sobre las otras tres (la media). Ignorando este caso, analizamos el resultado obtenido para los otros modelos, en los cuales se quiere predecir la nota final utilizando alguna otra variable o conjunto de variables.

De la tabla anterior, elegimos el modelo 8, que nos permitiría predecir la nota final a partir de la nota del segundo trimestre y de evaluar las variables *studytime* y *schoolsup*. Utilizando este modelo y el conjunto de datos de test que habiamos reservado podemos predecir las notas finales para estos estudiantes.

```{r message= TRUE, warning=FALSE}
y_predict = predict(modelo8, test)
```

En la siguiente gráfica mostramos el error cometido en cada una de las predicciones:

```{r message= TRUE, warning=FALSE}
data = data.frame(G2=test$score, pred=y_predict, se=abs(y_predict - test$score)) 
data$sample <- seq.int(nrow(data))
ggplot(data, aes(x=sample, y=pred)) + 
    geom_errorbar(aes(ymin=pred-se, ymax=pred+se)) +
    geom_point()
```

## Regresión logística
Vamos a utilizar regresión logística para intentar averiguar qué variable de las categóricas con las que hemos estado trabajando puede predecirse mejor a partir de la nota media dle curso. Vamos a generar modelos de regresión logística para distintas variables dicotómicas, y vamos a ver cuál de ellos es mejor.

Nos centraremos en las siguientes variables:

- Sexo: podemos predecir el sexo del alumno en función de la nota?
- SchoolSup: podemos predecir si el alumno ha tenido ayuda en la escuela en función de la nota media?
- famSup: podemos predecir si el alumno ha tenido ayuda en casa en función de la nota media?
- higher: Podemos predecir si el alumno querrá seguir estudiando en función de la nota media obtenida?




En primer lugar vamos a representar las observaciones para cada uno de estos casos para poder intuir gráficamente si la varibale escogida (la media de las notas: score) está relacionada con la variable respuesta (obtienen ayuda escolar) y puede considerarse que es un buen predictor

```{r message= FALSE, warning=FALSE}
par(mfrow=c(2,2))
ggplot(data = students, aes(x = sex, y = score, color = sex)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")

ggplot(data = students, aes(x = schoolsup, y = score, color = schoolsup)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")

ggplot(data = students, aes(x = famsup, y = score, color = famsup)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")


ggplot(data = students, aes(x = higher, y = score, color = higher)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1) +
  theme_bw() +
  theme(legend.position = "null")
```

A la vista de las gráficas, parece que en el único caso en el que se aprecian diferencias significativas en las notas es en el caso en el que los estudiantes quieren seguir estudiando.


Ahora vamos a generar los modelos para cada una de ellas a ver qué obtenemos

```{r message= FALSE, warning=FALSE}
m1 <- glm(sex ~ score, data = students, family = "binomial")
summary(m1)

m2 <- glm(schoolsup ~ score, data = students, family = "binomial")
summary(m2)

m3 <- glm(famsup ~ score, data = students, family = "binomial")
summary(m3)


m4 <- glm(higher ~ score, data = students, family = "binomial")
summary(m4)
```

Se observa que el AIC (criterio de información de Akaike) menor de los 4 modelos es el correspondiente al hecho de querer cursar estudios superiores


## Conclusiones

Hemos partido de un conjunto de datos de alumnos esudiantes de matemáticas y portugués en los que se recogía información de diferentes aspectos: el sexo de los alumnos, el número de suspensos, si reciben ayuda extra en sus estudios ya sea esta en el colegio, pagada por sus padres, si quieren continuar con sus estudios, y las notas obtenidas durante los tres trimestres.

Teníamos los datos de dos ficheros csv, uno para los datos de matemáticas y otro para los de portugés. Como primer paso, hemos unido ambos conjuntos en un único data set añadiendo una nueva columna indicando la asignatura de la que provenían. Una vez que los teníamos juntos hemos creado una varibale numérica nueva con la media de todas las notas y otra variable categórica asociando esa nota media a una nota categorizada (A, B, C, D, E y F). Tras comprobar que no existian valores nulos ni vacíos, hemos analizado los outliers que había en cada variable numérica y hemos tratado particularmente cada uno de ellos, teniendo en cuenta la relevancia de los mismos para cada uno de los casos.

El objetivo de nuestro estudio es saber si existe alguna variable en el juego de datos que pueda ayudarnos a predecir las notas. 

En primer lugar hemos analizado la correlación entre las notas: vemos que lo están, es decir, que las notas de cada alumno en cada trimestre están determinadas fuertemente por las obtenidas en los anteriores, es decir, que un estudiante que saca buenas notas en el primer trimestre es muy probable que saque buenas notas en los siguientes.

Además, hemos usado regresión logística para poder saber si las notas pueden determinar alguna de estas características, hemos intentando averiguar cuál de las variables binarias que tenemos puede estar determinada por las notas obtenidas y vemos que de todas las que hemos analizado, la más determinada es la voluntad del estudiante de continuar con cursos superiores, es decir, que podemos ver que un estudiante que ha obtenido una nota alta es probable que continúe sus estudios. Luego parece lógico pensar que un alumno que quiere continuar estudiando tendrá buenas calificaciones.


# Recursos

Los siguientes recursos son de utilidad para la realización de la práctica:
● Calvo M., Subirats L., Pérez D. (2019). Introducción a la limpieza y análisis de los datos.
Editorial UOC.
● Megan Squire (2015). Clean Data. Packt Publishing Ltd.
● Jiawei Han, Micheine Kamber, Jian Pei (2012). Data mining: concepts and techniques.
Morgan Kaufmann.
● Jason W. Osborne (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme
Scores. Newborn and Infant Nursing Reviews; 10 (1): pp. 1527-3369.
● Peter Dalgaard (2008). Introductory statistics with R. Springer Science & Business Media.
● Wes McKinney (2012). Python for Data Analysis. O’Reilley Media, Inc.
● Tutorial de Github https://guides.github.com/activities/hello-world.


  




